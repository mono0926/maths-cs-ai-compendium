# 行列の性質 (Matrix Properties)

- **行列 (matrix)** の本質は、数値を縦（行）と横（列）に並べた長方形の格子（グリッド）です。ベクトルが数値の単一のリストであるなら、行列はそれらを並べた表のようなものです。

```math
A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}
```

- 行列は、ベクトルの積み重ね（スタック）として考えることもできます。

- もし一人の人間がベクトル $[\text{年齢}, \text{身長}, \text{体重}]$ で記述されるなら、三人の人間は各行が一人の人間を表す行列を形成します：

```math
\begin{bmatrix} 25 & 170 & 65 \\ 30 & 180 & 80 \\ 22 & 160 & 55 \end{bmatrix}
```

- この行列は3行3列であるため、$3 \times 3$ 行列と呼ばれます。

- 格子内の各数値は **要素 (element)** または **成分 (entry)** と呼ばれ、行と列によって識別されます：$A_{ij}$ は $i$ 行 $j$ 列の要素を表します。

- 行列の **転置 (transpose)** は、対角線に沿って行列を反転させ、行を列に、列を行に入れ替える操作です。$A$ が $m \times n$ 行列であれば、$A^T$ は $n \times m$ 行列になります。

```math
A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix} \quad \Rightarrow \quad A^T = \begin{bmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{bmatrix}
```

- 行列とその転置を掛け合わせると、常に正方行列（行数と列数が等しい行列）が得られます。$AA^T$ は $m \times m$ 行列になり、$A^TA$ は $n \times n$ 行列になります。

- 正方行列の **トレース (trace)** は、対角要素の総和です：$\text{tr}(A) = A_{11} + A_{22} + \cdots + A_{nn}$。トレースは、固有値（後述）の合計に等しくなります。

![トレース：対角成分の和](../../images/matrix_trace.svg)

- 上記の行列の場合、$\text{tr}(A) = 1 + 4 + 9 = 14$ となります。強調表示された対角成分のみが計算に関係します。

- 2つの行列が、異なる基底の下で同じ線形変換を表している場合、それらのトレースは同じになります。つまり、トレースは「基底に依存しない」性質を持ちます。

- 行列の **ランク (rank)** は、線形独立な行（または列）の数です。これはその行列が持つ「有効な情報量」を示します。

- 例えば、以下の行列は一方の行がもう一方の定数倍ではないため、ランクは 2 です：

```math
\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}
```

しかし、以下の行列は2行目が1行目の単なる2倍であり、新しい情報を追加していないため、ランクは 1 になります：

```math
\begin{bmatrix} 1 & 2 \\ 2 & 4 \end{bmatrix}
```

- $5 \times 3$ 行列のランクは最大でも 3 です。いくつかの行が他の行のスケーリングや組み合わせである場合、ランクは低下します。可能な限り最大のランクを持つ行列を **フルランク (full rank)** と呼びます。

![ランク：独立した行が全空間を張る場合 vs 従属した行が部分空間のみを張る場合](../../images/matrix_rank.svg)

- 正方行列が正則（逆行列が存在する）であることと、それがフルランクであることは同値です。

- ランクは、**ランク・退化次数の定理 (rank-nullity theorem)** を通じて、**核 (null space)**（行列によってゼロに写されるベクトルの集合）と結びついています：$\text{rank}(A) + \text{nullity}(A) = A \text{の列数}$。行列が維持するもの（ランク）と破壊するもの（退化次数）を足すと、全次元数に等しくなります。

- 行列の **列空間 (column space)** は、行列に任意のベクトルを掛けたときに得られるすべての可能な出力の集合です。これは行列の列ベクトルによって張られます。行列に3本の列があっても独立なものが2本しかなければ、その列空間は3次元空間全体ではなく、2次元の平面になります。

![列空間：独立した列が平面を張る場合、従属した列が直線のみを張る場合](../../images/column_space.svg)

- **行空間 (row space)** も行の視点から見た同様の概念です。ランクは列空間の次元と行空間の次元の両方に等しいため、これらは常に一致します。

- 列空間は「この行列がどのような出力を生成できるか？」を、核（零空間）は「どのような入力がゼロに写されるか？」を教えてくれます。これら2つの空間によって、その行列の振る舞いが完全に記述されます。

- 正方行列の **行列式 (determinant)** は、行列が空間をどれくらいスケーリング（伸縮）させるかを捉える一つの数値です。$2 \times 2$ 行列を、単位正方形を平行四辺形に変換するものと考えてみてください。行列式はその平行四辺形の（符号付きの）面積に相当します。

```math
\det\begin{bmatrix} a & b \\ c & d \end{bmatrix} = ad - bc
```

![行列式：線形変換による面積のスケーリング係数](../../images/determinant.svg)

- 例：

```math
\det\begin{bmatrix} 2 & 1 \\ 0 & 3 \end{bmatrix} = 2 \cdot 3 - 1 \cdot 0 = 6
```

この変換によって、単位正方形は面積 6 の平行四辺形に引き伸ばされます。

- 行列式が正であれば、変換は向きを保持します。負であれば、向きを反転させます（鏡像反転など）。ゼロであれば、行列は空間をより低い次元に押しつぶし、平行四辺形を直線や点へと崩壊させます。

- 行列式がゼロである行列を **特異行列 (singular matrix)** と呼びます。逆行列が存在せず、データが恒久的に失われます。

- $2 \times 2$ より大きな行列の場合、行列式は **小行列式 (minors)** と **余因子 (cofactors)** を使って計算されます。小行列式 $M_{ij}$ は、$i$ 行と $j$ 列を削除して得られる一回り小さな行列の行列式です。

![小行列式：行と列を削除して小さな行列を得る](../../images/cofactor.svg)

- 余因子 $C_{ij} = (-1)^{i+j} M_{ij}$ は、各小行列式に（チェス盤のように交互に）符号を付けたものです。行列全体の行列式は、任意の行または列に沿った総和になります：$\det(A) = \sum_j A_{1j} \cdot C_{1j}$。これは **余因子展開** と呼ばれます。

- 正方行列 $A$ の **逆行列 (inverse)** $A^{-1}$ とは、$A$ が行った操作を元に戻す行列です：$AA^{-1} = A^{-1}A = I$ ($I$ は単位行列)。非特異行列（行列式がゼロでない行列）のみが逆行列を持ちます。

- $2 \times 2$ 行列の場合、逆行列の直接の公式があります：

```math
\begin{bmatrix} a & b \\ c & d \end{bmatrix}^{-1} = \frac{1}{ad - bc}\begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
```

分母に行列式が含まれていることに注目してください。これが、特異行列（行列式がゼロ）に逆行列が存在しない理由です。

- **条件数 (condition number)** は、入力の小さな変化に対して行列がいかに敏感であるかを測定します。$\kappa(A) = \|A\| \cdot \|A^{-1}\|$ として定義されます。

- 条件数が 1 に近い行列は **良条件 (well-conditioned)** であると言えます。入力の小さな変化は出力の小さな変化につながります。条件数が大きい行列は **悪条件 (ill-conditioned)** と呼ばれ、微細なエラーが劇的に増幅されます。直交行列や単位行列の条件数は 1 ですが、特異行列の条件数は無限大になります。

- 例えば、以下の行列の条件数は $10^8$ です。一つの方向は正常にスケールされますが、もう一つの方向はほぼゼロに押しつぶされているため、その方向へのわずかな乱れが激しく歪められます。

```math
\begin{bmatrix} 1 & 0 \\ 0 & 10^{-8} \end{bmatrix}
```

- ベクトルにノルム（長さ）があるように、行列にもその大きさを測る **ノルム (norms)** があります。最も一般的なのは **フロベニウスノルム** で、行列を一本の長いベクトルとみなしてその長さを計算します：

```math
\|A\|_F = \sqrt{\sum_{i}\sum_{j} A_{ij}^2}
```

- 例：

```math
\left\|\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}\right\|_F = \sqrt{1 + 4 + 9 + 16} = \sqrt{30} \approx 5.48
```

- **スペクトルノルム** $\|A\|_2$ は、$A$ の最大の特異値に相当します。これは、行列が単位ベクトルを最大でどれだけ引き伸ばせるかを測定します。MLでは、行列ノルムは重みの正則化（大きな重みへのペナルティ）や学習の安定性のモニタリングに使用されます。

- 対称行列 $A$ が **正定値 (positive definite)** であるとは、すべての非ゼロベクトル $\mathbf{x}$ に対して $\mathbf{x}^T A \mathbf{x} > 0$ が成り立つことを指します。この2次形式は常に正の数値を生成します。

- 例として、以下の行列は正定値です：

```math
A = \begin{bmatrix} 2 & 1 \\ 1 & 3 \end{bmatrix}
```

任意のベクトル、例えば $\mathbf{x} = [1, -1]^T$ を選ぶと：$\mathbf{x}^T A \mathbf{x} = 2 - 1 - 1 + 3 = 3 > 0$ となります。どのような非ゼロベクトル $\mathbf{x}$ を試しても、常に正の結果が得られます。

- 正定値行列が重要であるのは、最適化問題において一意の最小値が存在することを保証するためです。

- 条件を $\mathbf{x}^T A \mathbf{x} \geq 0$（ゼロを許容）に緩和した場合、その行列は **半正定値 (positive semi-definite, PSD)** と呼ばれます。PSD行列は、共分散行列、SVMのカーネル行列、局所最小点におけるヘッセ行列など、至る所に現れます。PSDとの違いは、一部の方向が厳密に上向きに湾曲するのではなく、「平坦」（曲率がゼロ）であることを許容する点です。

## コーディング課題 (CoLab または notebook を使用)

1. 行列のトレース、ランク、行列式を計算してください。一つの行を別の行の定数倍にしてみて、ランクと行列式がどのように変化するかを確認してください。

```python {cmd=true}
import jax.numpy as jnp

A = jnp.array([[1.0, 2.0],
               [3.0, 4.0]])

print(f"Trace: {jnp.trace(A)}")
print(f"Rank: {jnp.linalg.matrix_rank(A)}")
print(f"Determinant: {jnp.linalg.det(A):.2f}")
```

2. 行列の逆行列を計算し、元の行列と掛け合わせて単位行列が得られることを確認してください。その後、特異行列を試して何が起こるか観察してください。

```python {cmd=true}
import jax.numpy as jnp

A = jnp.array([[1.0, 2.0],
               [3.0, 4.0]])

A_inv = jnp.linalg.inv(A)
print(f"A * A_inv:\n{A @ A_inv}")
```
