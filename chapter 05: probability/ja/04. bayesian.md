# ベイズ手法と系列モデル

- これまでは分布と確率の計算方法について説明してきました。ここでは、機械学習の核心となる問いに取り組んでみましょう。観測されたデータが与えられたとき、モデルに最適なパラメータをどのように見つければよいでしょうか？

- **最大尤度推定 (Maximum Likelihood Estimation: MLE)** は、この問いに直接答えるものです。観測されたデータの発生確率を最大化するパラメータ値を選択します。

- 形式的には、データ $D = \{x_1, x_2, \ldots, x_n\}$ とパラメータ $\theta$ を持つモデルが与えられたとき、**尤度関数 (likelihood function)** は次のように定義されます。

$$L(\theta | D) = P(D | \theta) = \prod_{i=1}^{n} P(x_i | \theta)$$

- この積は、データポイントが独立同一分布 (independent and identically distributed: i.i.d.) であることを前提としています。MLEによる推定値は次のようになります。

$$\hat{\theta}_{\text{MLE}} = \arg\max_\theta L(\theta | D)$$

- 実際には、尤度の代わりに**対数尤度 (log-likelihood)** を最大化します。対数をとることで積が和に変換され、数値的なアンダーフローを防ぐことができるからです。

$$\ell(\theta) = \log L(\theta | D) = \sum_{i=1}^{n} \log P(x_i | \theta)$$

- $\log$ は単調増加関数であるため、$\ell(\theta)$ を最大化する $\theta$ は $L(\theta)$ も最大化します。

- **コイン投げの例**: コインを10回投げて7回表が出たとします。このコインの偏り $p$（表が出る確率）のMLE推定値は何でしょうか？

- 各試行はベルヌーイ分布 Bernoulli($p$) に従うため、10回中7回表が出る尤度は次のようになります。

$$L(p) = \binom{10}{7} p^7 (1-p)^3$$

- 対数をとり微分すると、$\frac{d\ell}{dp} = \frac{7}{p} - \frac{3}{1-p} = 0$ となり、$\hat{p}_{\text{MLE}} = 7/10 = 0.7$ が得られます。

- MLEは直感的でシンプルです。10回中7回表が出たなら、最も可能性の高い偏りは0.7です。しかし、問題もあります。もし10回中10回すべて表が出た場合、MLEは $\hat{p} = 1$、つまりこのコインは常に表が出ると判断します。わずか10回の観察でそう結論付けるのは、自信過剰に見えます。

- **最大事後確率推定 (Maximum A Posteriori: MAP)** は、事前の信念（事前知識）を加えることでこの問題を解決します。尤度だけを最大化するのではなく、MAPは事後確率を最大化します。

$$\hat{\theta}_{\text{MAP}} = \arg\max_\theta P(\theta | D) = \arg\max_\theta P(D | \theta) \cdot P(\theta)$$

- 分母の $P(D)$ は $\theta$ に依存せず、argmaxの結果に影響を与えないため省略しています。

- **事前分布 (prior)** $P(\theta)$ は、データを見る前に $\theta$ について信じている内容をエンコードしたものです。コインの偏りに対して Beta(2, 2) 事前分布（コインがほぼ公平であるという緩やかな信念）を使用すると、MAP推定値は単なる表の割合ではなくなり、0.5の方向へ引き寄せられます。

![MLEは尤度のピークを見つけ、MAPは「尤度 × 事前分布」のピークを見つける](../images/mle_vs_map.svg)

- Beta($\alpha$, $\beta$) 事前分布を用い、表 $h$ 回、裏 $t$ 回を観測した場合、事後分布は Beta($\alpha + h$, $\beta + t$) となり、MAP推定値は次のようになります。

$$\hat{p}_{\text{MAP}} = \frac{\alpha + h - 1}{\alpha + \beta + h + t - 2}$$

- 先ほどの例で Beta(2, 2) の事前分布、表7回、裏3回の場合、$\hat{p}_{\text{MAP}} = \frac{2 + 7 - 1}{2 + 2 + 10 - 2} = \frac{8}{12} = 0.667$ となります。

- MAP推定値 (0.667) が MLE (0.7) に比べて 0.5 の方向へ引き寄せられていることに注目してください。事前分布は正則化 (regularisation) として機能します。機械学習における L2 正則化（ウェイトデカレイ）は、重みに対してガウス分布の事前分布を仮定したMAP推定と全く等価です。

- **完全なベイズ推論 (Full Bayesian inference)** は、MAPよりもさらに踏み込みます。単一の最適な $\theta$ を見つけるのではなく、事後分布 $P(\theta | D)$ 全体を保持します。これにより、点推定だけでなく、不確実性の尺度も得られます。

- Beta(2, 2) 事前分布で表7回、裏3回の例では、事後分布全体は Beta(9, 5) です。この分布の平均は $9/14 \approx 0.643$ であり、分布の広がりは私たちの自信の度合いを示しています。データが増えるほど、事後分布は狭くなります。

- これら3つのアプローチは一つのスペクトルを形成しています。
  - **MLE**: 事前分布なし、データのみ。高速だが、データが少ないと過学習しやすい。
  - **MAP**: 事前分布による正則化を伴う点推定。堅牢性が増す。
  - **完全ベイズ**: 事後分布全体。最も情報量が多いが、計算コストが高くなることが多い。

- **マルコフ連鎖 (Markov chains)** は、次の状態が過去の履歴ではなく、現在の状態のみに依存するシーケンスをモデル化します。この「記憶を持たない」性質を**マルコフ性 (Markov property)** と呼びます。

$$P(X_{t+1} | X_t, X_{t-1}, \ldots, X_1) = P(X_{t+1} | X_t)$$

- 天気を例に考えてみましょう。明日の天気は今日の天気に依存しますが、先週の天気には依存しません（簡略化されていますが、驚くほど有用なモデルです）。

- マルコフ連鎖は、有限の**状態 (states)** の集合と、状態 $i$ から状態 $j$ への遷移確率を示す要素 $T_{ij}$ を持つ**遷移行列 (transition matrix)** $T$ によって定義されます。各行の和は1になります。

![状態として雨、晴れ、曇りを持ち、遷移確率が示された天気のマルコフ連鎖](../images/markov_chain.svg)

- 上記の天気例の場合、遷移行列は次のようになります。

```math
T = \begin{pmatrix} 0.3 & 0.4 & 0.3 \\ 0.2 & 0.5 & 0.3 \\ 0.4 & 0.3 & 0.3 \end{pmatrix}
```

- もし今日が雨（状態ベクトル $\mathbf{s}_0 = [1, 0, 0]$）なら、明日の天気の確率分布は $\mathbf{s}_1 = \mathbf{s}_0 T = [0.3, 0.4, 0.3]$ となります。2日後は $\mathbf{s}_2 = \mathbf{s}_0 T^2$ です。ここでは第1章で行列の掛け算を使用します。

- 多くのマルコフ連鎖は、$\pi T = \pi$ を満たす**定常分布 (stationary distribution)** $\pi$ に収束します。どこからスタートしても、十分なステップを経た後、連鎖は $\pi$ に落ち着きます。この性質は、ベイズ機械学習で広く使われるサンプリング手法である MCMC (Markov Chain Monte Carlo: マルコフ連鎖モンテカルロ法) の基礎となっています。

- **隠れマルコフモデル (Hidden Markov Models: HMM)** は、マルコフ連鎖に間接的な層を追加したものです。真の状態は隠れており（観測不能）、各時間ステップで隠れ状態が観測可能な信号を放出します。

![HMMの構造: 上部にある隠れ状態が遷移で結ばれ、下部にある観測値が出力確率で結ばれている](../images/hmm_structure.svg)

- HMMは3つの要素で構成されます。
  - **遷移確率 (Transition probabilities)** $P(z_t | z_{t-1})$: 隠れ状態がどのように変化するか（マルコフ連鎖）
  - **出力確率 (Emission probabilities)** $P(x_t | z_t)$: 各隠れ状態がどのような観測値を出力するか
  - **初期分布 (Initial distribution)** $P(z_1)$: 最初の隠れ状態の確率

- **傘の例**: 天気を直接見ることはできませんが、友人が傘を持っているかどうかを観察できるとします。隠れ状態は {雨, 晴れ} であり、観測値は {傘あり, 傘なし} です。

- 遷移確率: $P(\text{雨}|\text{雨}) = 0.7$, $P(\text{晴れ}|\text{雨}) = 0.3$, $P(\text{雨}|\text{晴れ}) = 0.4$, $P(\text{晴れ}|\text{晴れ}) = 0.6$
- 出力確率: $P(\text{傘あり}|\text{雨}) = 0.9$, $P(\text{傘なし}|\text{雨}) = 0.1$, $P(\text{傘あり}|\text{晴れ}) = 0.2$, $P(\text{傘なし}|\text{晴れ}) = 0.8$

- HMMにおける主要な問いは以下の通りです。
  - **デコーディング (Decoding)**: 観測値が与えられたとき、最も可能性の高い隠れ状態の系列は何か？ **ビタービアルゴリズム (Viterbi algorithm)** によって解決されます。
  - **評価 (Evaluation)**: ある観測系列が得られる確率はいくらか？ **前向きアルゴリズム (Forward algorithm)** によって解決されます。
  - **学習 (Learning)**: 観測値が与えられたとき、最適なモデルパラメータは何か？ **バウム・ウェルチアルゴリズム (Baum-Welch algorithm)**（期待値最大化法: EMアルゴリズムの一種）によって解決されます。

- **ビタービアルゴリズムの例**: [傘あり, 傘あり, 傘なし] という観測が得られたとき、最も可能性の高い天気の系列を見つけます。

- 初期確率を $P(\text{雨}) = 0.5, P(\text{晴れ}) = 0.5$ と仮定します。

- **1日目**（観測: 傘あり）:
  - $V_1(\text{雨}) = P(\text{雨}) \cdot P(\text{傘あり}|\text{雨}) = 0.5 \times 0.9 = 0.45$
  - $V_1(\text{晴れ}) = P(\text{晴れ}) \cdot P(\text{傘あり}|\text{晴れ}) = 0.5 \times 0.2 = 0.10$

- **2日目**（観測: 傘あり）:
  - $V_2(\text{雨}) = \max(V_1(\text{雨}) \cdot P(\text{雨}|\text{雨}), V_1(\text{晴れ}) \cdot P(\text{雨}|\text{晴れ})) \cdot P(\text{傘あり}|\text{雨})$
  - $= \max(0.45 \times 0.7, 0.10 \times 0.4) \times 0.9 = \max(0.315, 0.04) \times 0.9 = 0.2835$
  - $V_2(\text{晴れ}) = \max(V_1(\text{雨}) \cdot P(\text{晴れ}|\text{雨}), V_1(\text{晴れ}) \cdot P(\text{晴れ}|\text{晴れ})) \cdot P(\text{傘あり}|\text{晴れ})$
  - $= \max(0.45 \times 0.3, 0.10 \times 0.6) \times 0.2 = \max(0.135, 0.06) \times 0.2 = 0.027$

- **3日目**（観測: 傘なし）:
  - $V_3(\text{雨}) = \max(0.2835 \times 0.7, 0.027 \times 0.4) \times 0.1 = 0.1985 \times 0.1 = 0.01985$
  - $V_3(\text{晴れ}) = \max(0.2835 \times 0.3, 0.027 \times 0.6) \times 0.8 = 0.08505 \times 0.8 = 0.06804$

- 3日目の最大値は「晴れ」です。バックトラッキング（逆方向に辿る）を行うと、3日目 = 晴れ、2日目 = 雨、1日目 = 雨となります。最も可能性の高い系列は、**雨、雨、晴れ**です。

- **前向き後ろ向きアルゴリズム (Forward-Backward algorithm)** は、観測系列全体が与えられた条件下で、各時間ステップにおいて各隠れ状態にいる確率を計算します。前向きパスで $P(z_t, x_{1:t})$ を計算し、後ろ向きパスで $P(x_{t+1:T} | z_t)$ を計算します。これらを掛け合わせることで、平滑化された状態確率が得られます。

- **バウム・ウェルチアルゴリズム (Baum-Welch algorithm)** は、隠れ状態が観測されないデータからHMMのパラメータを学習します。これはEMアルゴリズムの一種です。Eステップでは前向き後ろ向き法を使用してどの隠れ状態が観測値を生成したかを推定し、Mステップでは遷移確率と出力確率を更新します。

- HMMは歴史的に、音声認識（隠れた音素状態が音響信号を放出する）やバイオインフォマティクス（隠れた遺伝子状態がDNA塩基対を放出する）の分野で主流でした。現在ではディープラーニングがこれらの分野でHMMに取って代わっていますが、隠れ状態、出力、系列推論というアイデアは、依然としてシーケンスモデルの中心的な概念です。

- **条件付き確率場 (Conditional Random Fields: CRF)** は、出力に関する独立性の仮定を取り除くことで、HMMを改良したものです。HMMでは、時刻 $t$ における観測は時刻 $t$ の隠れ状態のみに依存します。一方、CRFでは、位置 $t$ におけるラベルが入力系列全体に依存することを許容します。

- 線形連鎖CRFは、入力系列 $\mathbf{x}$ が与えられたときのラベル系列 $\mathbf{y}$ の条件付き確率をモデル化します。

$$P(\mathbf{y} | \mathbf{x}) = \frac{1}{Z(\mathbf{x})} \exp\!\left(\sum_t \left[\sum_k \lambda_k f_k(y_t, y_{t-1}, \mathbf{x}, t)\right]\right)$$

- ここで $f_k$ は特徴関数（入力の任意の部分を参照可能）、$\lambda_k$ は学習された重み、$Z(\mathbf{x})$ は正規化定数です。

- CRFは**判別モデル (discriminative model)**（$P(\mathbf{y}|\mathbf{x})$ を直接モデル化する）であるのに対し、HMMは**生成モデル (generative model)**（$P(\mathbf{x}, \mathbf{y})$ をモデル化する）です。この違いは、ロジスティック回帰（判別）とナイーブベイズ（生成）の違いと同じです。

- 現代の自然言語処理 (NLP) では、固有表現抽出や品詞タグ付けなど、ラベル間の依存関係を捉えることが重要なタスクにおいて、ニューラルネットワークの上層にCRF層が追加されることがよくあります (BiLSTM-CRF, BERT-CRFなど)。

## コーディングタスク (CoLab または notebook を使用)

1. コイン投げ実験の MLE と MAP を実装してください。異なる事前分布やデータ量によって MAP 推定値がどのように変化するか観察してください。

```python
import jax.numpy as jnp
import matplotlib.pyplot as plt

# データ: 観測されたコイン投げの結果
heads, tails = 7, 3

# MLE
p_mle = heads / (heads + tails)
print(f"MLE: {p_mle:.4f}")

# Beta事前分布を用いたMAP
for alpha, beta in [(1,1), (2,2), (5,5), (10,10)]:
    p_map = (alpha + heads - 1) / (alpha + beta + heads + tails - 2)
    print(f"MAP (Beta({alpha},{beta})): {p_map:.4f}")

# Beta(2,2)事前分布を用いた事後分布の可視化
theta = jnp.linspace(0.01, 0.99, 200)
# 事後分布は Beta(alpha+heads, beta+tails)
a_post, b_post = 2 + heads, 2 + tails
posterior = theta**(a_post-1) * (1-theta)**(b_post-1)
posterior = posterior / jnp.trapezoid(posterior, theta)

plt.figure(figsize=(8, 4))
plt.plot(theta, posterior, color="#e74c3c", linewidth=2, label=f"Posterior Beta({a_post},{b_post})")
plt.axvline(p_mle, color="#3498db", linestyle="--", label=f"MLE = {p_mle:.2f}")
plt.axvline((a_post-1)/(a_post+b_post-2), color="#e74c3c", linestyle="--", label=f"MAP = {(a_post-1)/(a_post+b_post-2):.3f}")
plt.xlabel("θ (coin bias)")
plt.ylabel("Density")
plt.title("Posterior distribution after 7H, 3T with Beta(2,2) prior")
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

2. 天気モデルのマルコフ連鎖を構築し、シミュレーションを行ってください。シミュレーションと $\pi T = \pi$ を解く方法の両方で定常分布を計算してください。

```python
import jax
import jax.numpy as jnp

# 遷移行列: 雨 (R), 晴れ (S), 曇り (C)
T = jnp.array([
    [0.3, 0.4, 0.3],
    [0.2, 0.5, 0.3],
    [0.4, 0.3, 0.3]
])
states = ["Rainy", "Sunny", "Cloudy"]

# 100,000ステップのシミュレーション
key = jax.random.PRNGKey(42)
n_steps = 100_000
state = 0  # 雨からスタート
counts = jnp.zeros(3)

for i in range(n_steps):
    key, subkey = jax.random.split(key)
    state = jax.random.choice(subkey, 3, p=T[state])
    counts = counts.at[state].add(1)

sim_stationary = counts / n_steps
print("Simulated stationary distribution:")
for s, p in zip(states, sim_stationary):
    print(f"  {s}: {p:.4f}")

# 理論解: 固有値1に対応する左固有値を見つける
eigenvalues, eigenvectors = jnp.linalg.eig(T.T)
idx = jnp.argmin(jnp.abs(eigenvalues - 1.0))
pi = jnp.real(eigenvectors[:, idx])
pi = pi / pi.sum()
print("\nAnalytical stationary distribution:")
for s, p in zip(states, pi):
    print(f"  {s}: {p:.4f}")
```

3. 傘のHMMに対するビタービアルゴリズムを実装し、観測系列をデコードしてください。

```python
import jax.numpy as jnp

# HMMパラメータ
states = ["Rainy", "Sunny"]
obs_names = ["Umbrella", "No umbrella"]

trans = jnp.array([[0.7, 0.3],   # R->R, R->S
                    [0.4, 0.6]])  # S->R, S->S

emit = jnp.array([[0.9, 0.1],    # R->U, R->noU
                   [0.2, 0.8]])   # S->U, S->noU

init = jnp.array([0.5, 0.5])

# 観測: 傘あり=0, 傘なし=1
observations = [0, 0, 1]  # 傘あり, 傘あり, 傘なし

def viterbi(obs, init, trans, emit):
    n_states = len(init)
    T = len(obs)
    V = jnp.zeros((T, n_states))
    path = jnp.zeros((T, n_states), dtype=int)

    # 初期化
    V = V.at[0].set(init * emit[:, obs[0]])

    # 再帰
    for t in range(1, T):
        for j in range(n_states):
            probs = V[t-1] * trans[:, j]
            V = V.at[t, j].set(jnp.max(probs) * emit[j, obs[t]])
            path = path.at[t, j].set(jnp.argmax(probs))

    # バックトラック
    best = [int(jnp.argmax(V[-1]))]
    for t in range(T-1, 0, -1):
        best.insert(0, int(path[t, best[0]]))
    return best, V

decoded, scores = viterbi(observations, init, trans, emit)
print("Observations:", [obs_names[o] for o in observations])
print("Decoded:     ", [states[s] for s in decoded])
```

4. コイン投げをより多く観察するにつれて事後分布がどのように進化するかを可視化してください。Beta(1,1) 事前分布（一様分布）から始め、各試行の後に更新してください。

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

theta = jnp.linspace(0.01, 0.99, 300)
key = jax.random.PRNGKey(7)

# 真の偏り = 0.65
flips = jax.random.bernoulli(key, p=0.65, shape=(50,))

plt.figure(figsize=(10, 5))
a, b = 1, 1  # Beta(1,1) = 一様分布

for n_obs in [0, 1, 5, 10, 25, 50]:
    h = int(flips[:n_obs].sum())
    t = n_obs - h
    a_post = a + h
    b_post = b + t
    y = theta**(a_post-1) * (1-theta)**(b_post-1)
    y = y / jnp.trapezoid(y, theta)
    plt.plot(theta, y, linewidth=2, label=f"n={n_obs} (h={h})")

plt.axvline(0.65, color="black", linestyle=":", alpha=0.5, label="true p=0.65")
plt.xlabel("θ")
plt.ylabel("Density")
plt.title("Bayesian updating: posterior narrows with more data")
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```
