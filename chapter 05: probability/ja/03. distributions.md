# 確率分布 (Probability Distributions)

- Chapter 4 では、確率変数、PMF（確率質量関数）、PDF（確率密度関数）、CDF（累積分布関数）について紹介しました。ここでは、機械学習や統計学で遭遇する最も重要な確率分布をカタログ化し、それぞれの直感的な理解、公式、平均、分散を示します。

- 3つの主要な関数の簡単な復習（詳細は Chapter 4 を参照）：
  - **PMF (確率質量関数)** $P(X = x)$：離散的な各結果の確率を与えます。棒グラフの各棒に相当します。
  - **PDF (確率密度関数)** $f(x)$：連続変数の各点における密度を与えます。2点間の曲線の下側の面積が確率になります。
  - **CDF (累積分布関数)** $F(x) = P(X \le x)$：$x$ までの累積確率。常に 0 から 1 の範囲をとり、減少することはありません。

- 分布の **サポート（支持集合; support）** とは、PMF または PDF が正の値をとる値の集合です。サイコロ投げの場合、サポートは $\{1,2,3,4,5,6\}$ です。正規分布の場合、サポートはすべての実数 $(-\infty, \infty)$ です。

- 分布は、離散分布（結果が数えられる、PMF を使用）と連続分布（結果が数えられない、PDF を使用）の2つのファミリーに明確に分けられます。

- **ベルヌーイ分布 (Bernoulli distribution)**：最も単純な分布です。「成功（1）」が確率 $p$、「失敗（0）」が確率 $1-p$ という、2つの結果しかない単一の試行を扱います。

$$P(X = x) = p^x (1 - p)^{1-x}, \quad x \in \{0, 1\}$$

- 平均：$E[X] = p$。分散：$\text{Var}(X) = p(1-p)$。

- すべてのコイン投げ、すべての「はい/いいえ」の分類、すべての二値の結果はベルヌーイ試行です。ML において、シグモイド関数の出力は、まさにベルヌーイ分布のパラメータ $p$ そのものです。

- **二項分布 (Binomial distribution)**：それぞれが同じ確率 $p$ を持つ $n$ 回の独立したベルヌーイ試行における、成功の回数をカウントします。

$$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad k = 0, 1, \ldots, n$$

- ファイル 01 で学んだ二項係数 $\binom{n}{k}$ は、$n$ 回の試行の中で $k$ 回の成功を配置する方法が何通りあるかをカウントします。

- 平均：$E[X] = np$。分散：$\text{Var}(X) = np(1-p)$。

![単一の棒グラフとしてのベルヌーイ分布 vs 回数の分布としての二項分布](../images/bernoulli_binomial.svg)

- 例：偏ったコイン ($p = 0.7$) を 8 回投げます。ちょうど 6 回表が出る確率は $\binom{8}{6}(0.7)^6(0.3)^2 = 28 \times 0.1176 \times 0.09 \approx 0.296$ です。

- **ポアソン分布 (Poisson distribution)**：既知の平均発生率 $\lambda$ が与えられたとき、一定の時間や空間の間隔におけるイベントの発生回数をカウントします。イベントが稀で、かつ独立している場合に有用です。

$$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, 2, \ldots$$

- 平均：$E[X] = \lambda$。分散：$\text{Var}(X) = \lambda$。平均と分散が等しくなるのが、この分布の特徴的な性質です。

- 例：1時間あたりのメール受信数 ($\lambda = 5$)、1ページあたりの誤字数、1秒あたりのサーバーリクエスト数など。ML では、線形モデルでは負の値を予測してしまうようなカウントデータのモデリングにポアソン回帰が使われます。

- $n \to \infty$ かつ $p \to 0$ で、$np = \lambda$ を一定に保つとき、二項分布 Binomial$(n,p)$ はポアソン分布 Poisson$(\lambda)$ に収束します。これが、ポアソン分布が大規模集団における稀なイベントに対してうまく機能する理由です。

- **幾何分布 (Geometric distribution)**：最初の成功が得られるまでの試行回数をカウントします。「最初に表が出るまでに、何回コインを投げる必要があるか？」という問いです。

$$P(X = k) = (1-p)^{k-1} p, \quad k = 1, 2, 3, \ldots$$

- 平均：$E[X] = 1/p$。分散：$\text{Var}(X) = (1-p)/p^2$。

- 幾何分布には **無記憶性 (memoryless)** があります。さらに $k$ 回試行して成功する確率は、それまでに何回待ったかには依存しません。これは離散分布の中では特別な性質です。

- **負の二項分布 (Negative Binomial distribution)**：幾何分布を一般化したもので、$r$ 回目の成功が得られるまでの試行回数をカウントします（幾何分布は $r=1$ の特殊なケースです）。

$$P(X = k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}, \quad k = r, r+1, r+2, \ldots$$

- 平均：$E[X] = r/p$。分散：$\text{Var}(X) = r(1-p)/p^2$。

- 負の二項分布は、実務においてポアソン分布では扱いきれない、分散が平均を超えるような「過分散 (overdispersed)」なカウントデータをモデル化するためにも使用されます。

- ここからは連続分布に移ります。

- **一様分布 (Uniform distribution)**：区間 $[a, b]$ 内のすべての値が同様に確からしい分布です。PDF は平坦な長方形になります。

$$f(x) = \frac{1}{b - a}, \quad a \le x \le b$$

- 平均：$E[X] = \frac{a+b}{2}$。分散：$\text{Var}(X) = \frac{(b-a)^2}{12}$。

- 乱数生成器（RNG）は、まず Uniform(0,1) のサンプルを生成し、それを変換することで他の分布を生成するのが一般的です。

- **正規分布 / ガウス分布 (Normal / Gaussian distribution)**：統計学において最も重要な分布です。これは **中心極限定理**（Chapter 4 参照）から自然に導かれます。多くの独立した確率変数の平均は、元の分布に関わらず正規分布に近づく性質があります。

$$f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\!\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)$$

- 平均：$E[X] = \mu$。分散：$\text{Var}(X) = \sigma^2$。

- **標準正規分布** は $\mu = 0$、$\sigma = 1$ のケースです。任意の正規分布に従う変数 $X$ は、$Z = (X - \mu)/\sigma$ とすることで標準正規分布 $Z$ に標準化できます。

![経験則（68-95-99.7 ルール）の領域が色付けされたベルカーブ](../images/normal_empirical.svg)

- **経験則 (empirical rule / 68-95-99.7 rule)** によれば：
  - データの約 68% が平均から $\pm 1\sigma$ の範囲に収まる
  - 約 95% が $\pm 2\sigma$ の範囲に収まる
  - 約 99.7% が $\pm 3\sigma$ の範囲に収まる

- ML において、正規分布は至る所に現れます：重みの初期化、データ拡張におけるノイズ付加、MSE（平均二乗誤差）損失が暗黙的に仮定しているガウス誤差、変分オートエンコーダ (VAE) における再パラメータ化トリック (reparameterisation trick) などです。

- **指数分布 (Exponential distribution)**：ポアソン過程における「イベント間の時間」をモデル化します。イベントが平均レート $\lambda$ で発生する場合、その発生間隔は Exponential$(\lambda)$ に従います。

$$f(x) = \lambda e^{-\lambda x}, \quad x \ge 0$$

- 平均：$E[X] = 1/\lambda$。分散：$\text{Var}(X) = 1/\lambda^2$。

- 離散変数の幾何分布と同様に、指数分布も **無記憶性** を持ちます：$P(X > s + t | X > s) = P(X > t)$。さらに $t$ 時間待つ確率は、それまでにどれだけ待ったかには影響されません。

- **ガンマ分布 (Gamma distribution)**：指数分布を一般化したものです。ポアソン過程において $\alpha$ 番目のイベントが発生するまでの時間をモデル化します（指数分布は $\alpha = 1$ です）。

$$f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x}, \quad x > 0$$

- ここで $\alpha$ (shape) は形状を制御し、$\beta$ (rate) は尺度を制御します。$\Gamma(\alpha)$ はガンマ関数であり、階乗を実数に拡張したものです（正の整数に対しては $\Gamma(n) = (n-1)!$ です）。

- 平均：$E[X] = \alpha/\beta$。分散：$\text{Var}(X) = \alpha/\beta^2$。

- **ベータ分布 (Beta distribution)**：区間 $[0, 1]$ で定義され、確率、割合、比率などのモデリングに最適です。

$$f(x) = \frac{x^{\alpha - 1}(1 - x)^{\beta - 1}}{B(\alpha, \beta)}, \quad 0 \le x \le 1$$

- 分母の $B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$ はベータ関数と呼ばれる正規化定数です。

- 平均：$E[X] = \frac{\alpha}{\alpha + \beta}$。分散：$\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$。

- ベータ分布は、ベルヌーイ分布や二項分布の尤度に対する **共役事前分布 (conjugate prior)** です。これは、もし事前分布がベータ分布でデータが二項分布であれば、事後分布もまたベータ分布になることを意味し、ベイズ更新が解析的に扱いやすくなります。これについてはファイル 04 で使用します。

![4つの一般的な分布の形状：一様分布、指数分布、ベータ分布、ポアソン分布](../images/common_distributions.svg)

- **カイ二乗分布 ($\chi^2$ distribution)**：$k$ 個の独立した標準正規分布に従う確率変数の二乗和をとると、自由度 $k$ のカイ二乗分布に従います。

$$f(x) = \frac{1}{2^{k/2}\Gamma(k/2)} x^{k/2 - 1} e^{-x/2}, \quad x > 0$$

- 平均：$E[X] = k$。分散：$\text{Var}(X) = 2k$。

- カイ二乗分布は、実際には $\alpha = k/2, \beta = 1/2$ としたガンマ分布の特殊なケースです。これは仮説検定（Chapter 4 のカイ二乗検定）、適合度検定、および分散の信頼区間の計算などで登場します。

- **スチューデントの t 分布 (Student's t-distribution)**：正規分布に似ていますが、より裾が重い (heavier tails) のが特徴です。正規分布に従う母集団の平均を、母分散が未知の状態で、かつ少数のサンプルから推定する場合に発生します。

$$f(x) = \frac{\Gamma\!\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\,\Gamma\!\left(\frac{\nu}{2}\right)} \left(1 + \frac{x^2}{\nu}\right)^{-(\nu+1)/2}$$

- パラメータ $\nu$ (nu; ニュー) は自由度です。$\nu \to \infty$ となると、t 分布は標準正規分布に収束します。$\nu$ が小さいとき、裾が重いことは極端な値に高い確率を割り当てることを意味し、サンプルが少ないことによる不確実性の増大を反映しています。

- 平均：$E[X] = 0$ ($\nu > 1$ の場合)。分散：$\text{Var}(X) = \frac{\nu}{\nu - 2}$ ($\nu > 2$ の場合)。

- t 分布は t 検定 (Chapter 4) で使用されるほか、ベイズ推論において未知の分散を積分消去した際の周辺分布としても現れます。

- 主要な分布のまとめ：

| 分布                             | 型   | サポート           | 平均                    | 分散             |
| -------------------------------- | ---- | ------------------ | ----------------------- | ---------------- |
| ベルヌーイ分布$(p)$              | 離散 | $\{0,1\}$          | $p$                     | $p(1-p)$         |
| 二項分布$(n,p)$                  | 離散 | $\{0,\ldots,n\}$   | $np$                    | $np(1-p)$        |
| ポアソン分布$(\lambda)$          | 離散 | $\{0,1,2,\ldots\}$ | $\lambda$               | $\lambda$        |
| 幾何分布$(p)$                    | 離散 | $\{1,2,3,\ldots\}$ | $1/p$                   | $(1-p)/p^2$      |
| 一様分布$(a,b)$                  | 連続 | $[a,b]$            | $(a+b)/2$               | $(b-a)^2/12$     |
| 正規分布$(\mu,\sigma^2)$         | 連続 | $(-\infty,\infty)$ | $\mu$                   | $\sigma^2$       |
| 指数分布$(\lambda)$              | 連続 | $[0,\infty)$       | $1/\lambda$             | $1/\lambda^2$    |
| ガンマ分布$(\alpha,\beta)$       | 連続 | $(0,\infty)$       | $\alpha/\beta$          | $\alpha/\beta^2$ |
| ベータ分布$(\alpha,\beta)$       | 連続 | $[0,1]$            | $\alpha/(\alpha+\beta)$ | 上記参照         |
| カイ二乗分布$(k)$                | 連続 | $(0,\infty)$       | $k$                     | $2k$             |
| スチューデントの $t$ 分布$(\nu)$ | 連続 | $(-\infty,\infty)$ | $0$                     | $\nu/(\nu-2)$    |

## コーディングタスク (CoLab または notebook を使用)

1. $n=20$ の二項分布の PMF を、いくつかの $p$ の値についてプロットしてください。形状が左に歪んだ（左裾が長い）ものから対称、そして右に歪んだ（右裾が長い）ものへと変化する様子を観察してください。

```python
import jax.numpy as jnp
import matplotlib.pyplot as plt
from math import comb

n = 20
ks = jnp.arange(0, n + 1)

fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)
for ax, p, color in zip(axes, [0.2, 0.5, 0.8], ["#e74c3c", "#3498db", "#27ae60"]):
    pmf = jnp.array([comb(n, int(k)) * p**k * (1-p)**(n-k) for k in ks])
    ax.bar(ks, pmf, color=color, alpha=0.7)
    ax.set_title(f"Binomial(n={n}, p={p})")
    ax.set_xlabel("k")
axes[0].set_ylabel("P(X = k)")
plt.tight_layout()
plt.show()
```

2. 二項分布のポアソン近似を検証してください。$n = 1000, p = 0.003$ とし、二項分布$(n, p)$ とポアソン分布$(\lambda = np)$ を比較してください。

```python
import jax.numpy as jnp
import matplotlib.pyplot as plt
from math import comb, factorial, exp

n, p = 1000, 0.003
lam = n * p
ks = jnp.arange(0, 15)

binom_pmf = jnp.array([comb(n, int(k)) * p**k * (1-p)**(n-k) for k in ks])
poisson_pmf = jnp.array([lam**k * exp(-lam) / factorial(int(k)) for k in ks])

plt.figure(figsize=(8, 4))
plt.bar(ks - 0.15, binom_pmf, width=0.3, color="#3498db", alpha=0.7, label=f"Binomial({n},{p})")
plt.bar(ks + 0.15, poisson_pmf, width=0.3, color="#e74c3c", alpha=0.7, label=f"Poisson({lam})")
plt.xlabel("k")
plt.ylabel("P(X = k)")
plt.title("二項分布のポアソン近似")
plt.legend()
plt.show()
```

3. 正規分布からサンプルを抽出し、経験則を検証してください。サンプルが 1、2、3 標準偏差以内に収まる割合をカウントしてください。

```python
import jax
import jax.numpy as jnp

key = jax.random.PRNGKey(42)
mu, sigma = 5.0, 2.0
samples = mu + sigma * jax.random.normal(key, shape=(100_000,))

for k in [1, 2, 3]:
    within = jnp.abs(samples - mu) <= k * sigma
    print(f"{k}σ 以内: {within.mean():.4f} (理論値: {[0.6827, 0.9545, 0.9973][k-1]:.4f})")
```

4. $\alpha$ と $\beta$ を変化させて、ベータ分布を探索してください。いくつかの形状をプロットし、分布が一様から歪んだ形、そして集中した形へとどのように変化するかを確認してください。

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

x = jnp.linspace(0.01, 0.99, 200)

def beta_pdf(x, a, b):
    # 形状比較のため正規化なしの状態
    return x**(a-1) * (1-x)**(b-1)

plt.figure(figsize=(10, 5))
params = [(1,1,"Uniform"), (2,5,"Left skew"), (5,2,"Right skew"),
          (5,5,"Symmetric"), (0.5,0.5,"U-shape")]
colors = ["#999", "#e74c3c", "#3498db", "#27ae60", "#9b59b6"]

for (a, b, label), color in zip(params, colors):
    y = beta_pdf(x, a, b)
    y = y / jnp.trapezoid(y, x)  # 正規化
    plt.plot(x, y, label=f"α={a}, β={b} ({label})", color=color, linewidth=2)

plt.xlabel("x")
plt.ylabel("密度")
plt.title("ベータ分布の様々な形状")
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```
