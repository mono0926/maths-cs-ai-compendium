# スケーリングとデプロイ

- **モデル並列化**: テンソル並列 (Megatron 方式の列/行分割)、パイプライン並列 (GPipe、マイクロバッチ)、シーケンス並列
- **推論におけるデータ並列**: 複数の GPU にモデルを複製
- **分散 KV キャッシュ**: ノード間でのシャーディング、通信オーバーヘッド
- **推測デコード (Speculative decoding)**: ドラフトモデル + 検証、Medusa heads、EAGLE、自己推測デコード (Self-speculative decoding)
- **プレフィックス・キャッシュ (Prefix caching)**: 共通のプレフィックスを持つリクエスト間で KV キャッシュを共有
- **推論フレームワーク**: vLLM、TensorRT-LLM、SGLang、llama.cpp、TGI
- **コスト最適化**: スポットインスタンス、オートスケーリング、適切な GPU の選択 (Right-sizing)
- **モニタリング**: トークンレベルのロギング、レイテンシのヒストグラム、性能劣化の検出
