# 量子化 (Quantisation)

- **量子化の目的**: メモリ使用量の削減、スループットの向上、省電力化
- **数値フォーマット**: FP32、FP16、BF16、FP8 (E4M3、E5M2)、INT8、INT4、バイナリ/ターナリ (三値)
- **ポストトレーニング量子化 (PTQ)**: キャリブレーション、最小・最大 (Min-Max)、パーセンタイル、MSE 最適スケーリング
- **量子化を考慮した学習 (QAT)**: 擬似量子化 (Fake quantisation)、ストレートスルー推定法 (Straight-through estimator)
- **重みのみの量子化 (Weight-only quantisation)**: GPTQ、AWQ、QuIP、Squeeze-and-multiply
- **アクティベーションの量子化**: 動的 vs 静的、テンソル単位 vs チャネル単位 vs トークン単位
- **混合精度 (Mixed-precision)**: レイヤーごとの精度の選択、感度分析
- **KV キャッシュの量子化**: 長いシーケンスにおけるメモリ使用量の削減
