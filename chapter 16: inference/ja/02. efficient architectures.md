# 効率的なアーキテクチャ

- **StreamingLLM**: Attention sinks、ローリング KV キャッシュ、無限長の生成
- **スパース Attention**: ローカル Attention、スライディング・ウィンドウ (Mistral)、拡張 (Dilated)、BigBird、Longformer
- **線形 Attention**: カーネル近似、RWKV、RetNet、Mamba (状態空間モデル: SSM)
- **Multi-query attention (MQA) および Grouped-query attention (GQA)**: KV キャッシュのサイズの削減
- **推論における Mixture of Experts (MoE)**: エキスパート・キャッシュ、ルーティングの効率化
- **知識蒸留 (Knowledge distillation)**: 教師・生徒モデル、タスク固有 vs 汎用的な蒸留
- **プルーニング (枝刈り)**: 非構造化 (大きさベース)、構造化 (チャネル/ヘッドのプルーニング)、宝くじ仮説 (Lottery ticket hypothesis)
- **効率的なモデルのためのニューラルアーキテクチャ探索 (NAS)**
