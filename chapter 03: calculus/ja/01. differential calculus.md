# 微分学 (Differential Calculus)

- 前の章では、データをベクトルとして表現し、行列で変換する方法を学びました。しかし、現実世界の現象の多くは静的なものではありません。車は加速し、株価は変動し、ニューラルネットワークの損失は重みの更新とともに変化します。**微分積分学 (Calculus)** は「変化」の数学です。

- 微分積分学には2つの問いがあります。「今、どのくらいの速さで変化しているか？」（微分学）と「時間の経過とともにどれだけ蓄積されたか？」（積分学）です。このセクションでは「どのくらいの速さか」という問いに取り組みます。

- 運転中にスピードメーターに目を向けたと想像してください。そこには 60 km/h と表示されています。その数字は旅行全体の平均速度ではなく、その一瞬の速度です。微分学は、このような瞬間的な変化率を計算するためのツールを提供してくれます。

- しかしその前に、直線の方程式 $y = mx + b$ を復習しましょう。

- これは2つの量の間の最も単純な関係です。
  - $b$ は **y切片** であり、直線が y 軸と交わる点（$x = 0$ のときの開始値）です。
  - $m$ は **傾き (slope)** であり、変化率を表します。$x$ が 1 単位増加するごとに、$y$ は $m$ だけ変化します。

- $m = 3$ なら直線は急に上昇し、$m = 0$ なら水平になり、$m = -2$ なら下降します。

- 傾きは $m = \frac{\Delta y}{\Delta x} = \frac{y_2 - y_1}{x_2 - x_1}$ として計算されます。これは「$y$ がどれだけ変化したか」と「$x$ がどれだけ変化したか」の比率です。

![直線の式：b は y 切片、m は傾き](../images/line_equation.svg)

- $m$ と $b$ さえ分かれば、任意の $x$ に対して $y$ を計算できます。

- 例えば $m = 2, b = 3$ の場合、$x = 5$ のときは $y = 2(5) + 3 = 13$ となります。

- この2つのパラメータが直線を完全に決定し、出力を予測するには値を代入するだけです。

- 直線の場合、傾きはどこでも同じです。

- この考え方は直線以外にも一般化できます。非線形の関数は入力を出力にマッピングする規則であり、その数式（パラメータと形）が分かれば、任意の入力に対して出力を計算し、その結果をプロットできます。

- $y = x^2$ は放物線、$y = \sin(x)$ は波、$y = e^x$ は指数関数的な成長を示します。それぞれの数式が特定の曲線を定義しており、関数を図形として読めるようになることは、これ以降のすべての学習において不可欠です。

- 直線では傾きは一定ですが、興味深い関数の多くは曲線であり、傾きは点ごとに異なります。微分学は、曲線上の任意の1点における傾きを見つける方法を教えてくれます。

- また、**極限 (limit)** という概念も必要です。極限とは、入力がある目標値に（必ずしも到達することなく）どんどん近づいていくときに、関数がどのような値に近づくかを表します。

$$\lim_{x \to a} f(x) = L$$

- これは「$x$ が $a$ に近づくとき、$f(x)$ は $L$ に近づく」と読みます。$x = a$ において関数が実際に $L$ に等しくなる必要はありません。ただ、限りなく近づけばよいのです。

- 例えば、$f(x) = \frac{x^2 - 1}{x - 1}$ を考えてみましょう。直接 $x = 1$ を代入すると $\frac{0}{0}$ となり、未定義になります。

- しかし、1に近い値を試してみます：$f(0.9) = 1.9, f(0.99) = 1.99, f(1.01) = 2.01$。出力が明らかに 2 に向かっているのが分かります。

- 代数的には、分子を $(x-1)(x+1)$ と因数分解し、$(x-1)$ をキャンセルすると、$x \neq 1$ であるすべての $x$ に対して $f(x) = x + 1$ となることが分かります。したがって、$x \to 1$ のとき $f(x) \to 2$ です。

- 関数には $x = 1$ の位置に穴が開いていますが、極限は依然として存在します。

- 極限は、微分積分学の他のすべてが立脚している基礎です。

- 関数 $f(x)$ の点 $x = a$ における **微分 (derivative)** は、瞬間的な変化率を測定します。幾何学的には、その点における曲線の接線の傾きです。

![微分はその点における接線の傾きである](../images/tangent_line.svg)

- この傾きを計算するために、曲線上の2点から始め、それらを通る直線（**割線 (secant line)**）の傾きを計算します。次に、2番目の点を最初の点に限りなく近づけていき、割線の傾きがどのような値に近づくかを確認します。これを **差分商 (difference quotient)** と呼びます：

$$f'(a) = \lim_{h \to 0} \frac{f(a + h) - f(a)}{h}$$

![h が小さくなるにつれて、割線は接線に近づく](../images/difference_quotient.svg)

- 分子の $f(a+h) - f(a)$ は出力の変化量です。分母の $h$ は入力の変化量です。それらの比率は、ごく微小な区間における平均変化率です。$h \to 0$ とすると、この平均は瞬間的な変化率になります。

- 例えば、$f(x) = x^2$ とします。$x = 3$ においては：

$$f'(3) = \lim_{h \to 0} \frac{(3+h)^2 - 9}{h} = \lim_{h \to 0} \frac{9 + 6h + h^2 - 9}{h} = \lim_{h \to 0} (6 + h) = 6$$

- つまり、$x = 3$ において、関数 $x^2$ は入力 1 単位に対して出力が 6 単位の割合で増加しています。

- ある点においてこの極限が存在するとき、その関数はその点で **微分可能 (differentiable)** であると言います。そのためには、関数が連続（飛躍がない）であり、滑らか（尖った角がない）であり、その点の近傍で定義されている必要があります。

- ペンを離さずに、かつキンク（折れ曲がり）なしで曲線を描けるなら、その点でおそらく微分可能です。

- 毎回極限の定義から微分を計算するのは大変です。幸いなことに、いくつかのルールを使えば、ほとんどすべての関数を素早く微分できます。

- **定数のルール**: 定数の微分はゼロです。$f(x) = 5$ なら、$f'(x) = 0$ です。水平な線の傾きはゼロです。

- **べき乗のルール (Power rule)**: 微分の主力選手です。指数を前に出し、指数を 1 減らします：

$$\frac{d}{dx} x^n = n x^{n-1}$$

- 例えば：$\frac{d}{dx} x^3 = 3x^2$。3次式が2次式になります。これは、負の数や分数を含む任意の実行数に対して有効です：$\frac{d}{dx} x^{-1} = -x^{-2}$ や $\frac{d}{dx} \sqrt{x} = \frac{d}{dx} x^{1/2} = \frac{1}{2}x^{-1/2}$。

- **和/差のルール**: 各項を個別に微分します。

$$\frac{d}{dx}[f(x) \pm g(x)] = f'(x) \pm g'(x)$$

- **積のルール (Product rule)**: 2つの関数が掛け合わされているとき、微分は単に微分の積にはなりません。代わりに：

$$\frac{d}{dx}[f(x) \cdot g(x)] = f'(x)g(x) + f(x)g'(x)$$

- これを「1つ目の微分 $\times$ 2つ目 ＋ 1つ目 $\times$ 2つ目の微分」と覚えましょう。例えば、$\frac{d}{dx}[x^2 \sin x] = 2x \sin x + x^2 \cos x$ です。

- **商のルール (Quotient rule)**: 関数のは比の場合：

$$\frac{d}{dx}\left[\frac{f(x)}{g(x)}\right] = \frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2}$$

- 分母は「下の2乗」になります。

- **連鎖律 (Chain rule)**: 機械学習において最も重要なルールです。関数が合成されている（一方がもう一方の中に入っている）とき、微分は連鎖に沿った微分の積になります：

$$\frac{d}{dx} f(g(x)) = f'(g(x)) \cdot g'(x)$$

- 玉ねぎの皮を剥くように考えてください。外側の関数を微分し（内側の関数はそのまま）、それに内側の関数の微分を掛けます。

![連鎖律：外側を微分し、それに内側の微分を掛ける](../images/chain_rule.svg)

- 例えば、$\frac{d}{dx} (3x + 1)^5 = 5(3x+1)^4 \cdot 3 = 15(3x+1)^4$。外側の関数は $(\cdot)^5$ で、内側は $3x+1$ です。

- 連鎖律は、ニューラルネットワークにおける **誤差逆伝播法 (backpropagation)** の数学的基礎です。深いネットワークは、合成された関数の長い連鎖です。各重みに対して損失がどのように変化するかを計算するために、出力層から入力層に向かって連鎖律を繰り返し適用し、各ステップで局所的な微分を掛け合わせます。

- ここに、よく遭遇する主要な微分をまとめます。それぞれ極限の定義から導き出すことができますが、覚えておくと時間の節約になります：

| 関数       | 導関数              | 備考                             |
| ---------- | ------------------- | -------------------------------- |
| $e^x$      | $e^x$               | 自分自身が導関数となる唯一の関数 |
| $a^x$      | $a^x \ln a$         | 指数関数の一般化                 |
| $\ln x$    | $\frac{1}{x}$       | 自然対数                         |
| $\log_a x$ | $\frac{1}{x \ln a}$ | 一般の対数                       |
| $\sin x$   | $\cos x$            |                                  |
| $\cos x$   | $-\sin x$           | 負の符号に注意                   |
| $\tan x$   | $\sec^2 x$          |                                  |

- 指数関数 $e^x$ は注目に値します。自分自身が導関数に等しい唯一の関数だからです。そのため、Softmax 活性化関数から確率分布まで、ML のあらゆる場所に $e$ が登場します。

- **ロピタルの定理 (L'Hopital's Rule)** は、$\frac{0}{0}$ や $\frac{\infty}{\infty}$ のような不定形を生み出す極限を扱います。直接代入してこれらの形式になる場合、分子と分母を個別に微分してから、再度極限を試みることができます：

$$\lim_{x \to a} \frac{f(x)}{g(x)} = \lim_{x \to a} \frac{f'(x)}{g'(x)}$$

- 条件：$f$ と $g$ が $a$ の近くで微分可能であり、$a$ の近くで $g'(x) \neq 0$ であること（$a$ 自体は除く）。また、元の極限が不定形である必要があります。

- 例えば：$\lim_{x \to 0} \frac{\sin x}{x}$。直接代入すると $\frac{0}{0}$ です。ロピタルの定理を適用すると：$\lim_{x \to 0} \frac{\cos x}{1} = 1$。この極限は非常に基本的で、信号処理やフーリエ解析に登場します。

- 結果が依然として不定形である場合は、このルールを繰り返し適用できます。例えば、$\lim_{x \to 0} \frac{1 - \cos x}{x^2}$ は $\frac{0}{0}$ です。1回目の適用：$\lim_{x \to 0} \frac{\sin x}{2x}$（まだ $\frac{0}{0}$）。2回目の適用：$\lim_{x \to 0} \frac{\cos x}{2} = \frac{1}{2}$。

- 2つの関数が微分可能であれば、それらの和、差、積、合成、および商（分母がゼロでない場合）もすべて微分可能です。これが、単純なパーツから構築された複雑な数式を、私たちは自信を持って微分できる理由です。

## コーディングタスク (CoLab または notebook を使用)

1. 一般的な関数を可視化しましょう。$x^2, \sin(x), e^x$ を並べてプロットし、異なる数式がどのように異なる形状を生み出すかの直感を養います。パラメータを変更してみて（例：$2x^2, \sin(2x)$）、曲線がどのように変化するかを観察してください。

```python
import jax.numpy as jnp
import matplotlib.pyplot as plt

x = jnp.linspace(-3, 3, 300)

fig, axes = plt.subplots(1, 3, figsize=(12, 3))
axes[0].plot(x, x**2, color="#e74c3c")
axes[0].set_title("x²  (parabola)")
axes[1].plot(x, jnp.sin(x), color="#3498db")
axes[1].set_title("sin(x)  (wave)")
axes[2].plot(x, jnp.exp(x), color="#27ae60")
axes[2].set_title("eˣ  (exponential)")
for ax in axes:
    ax.axhline(0, color="gray", linewidth=0.5)
    ax.axvline(0, color="gray", linewidth=0.5)
plt.tight_layout()
plt.show()
```

2. JAX の自動微分を使用して、いくつかの点における $f(x) = x^3 - 2x + 1$ の微分を計算します。手計算による導関数 $f'(x) = 3x^2 - 2$ と比較してください。

```python
import jax
import jax.numpy as jnp

f = lambda x: x**3 - 2*x + 1
df = jax.grad(f)

for x in [0.0, 1.0, 2.0, -1.0]:
    print(f"x={x:5.1f}  autodiff: {df(x):.4f}  analytical: {3*x**2 - 2:.4f}")
```

3. 連鎖律を数値的に検証します。$f(x) = \sin(x^2)$ を定義し、`jax.grad` を通じてその微分を計算し、手計算の結果 $2x\cos(x^2)$ と比較します。

```python
import jax
import jax.numpy as jnp

f = lambda x: jnp.sin(x**2)
df = jax.grad(f)

for x in [0.5, 1.0, 2.0]:
    auto = df(x)
    analytical = 2*x * jnp.cos(x**2)
    print(f"x={x:.1f}  autodiff: {auto:.6f}  analytical: {analytical:.6f}")
```

4. 導関数を可視化します。$f(x) = x^3 - 3x$ とその導関数 $f'(x) = 3x^2 - 3$ を同じグラフ上にプロットします。$f'(x) = 0$ となる点が、$f$ の山や谷に対応していることに注目してください。

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

f = lambda x: x**3 - 3*x
# jax.grad はスカラーに対して動作します。jax.vmap はそれをベクトル化し、配列入力に対して一度に動作するようにします。
df = jax.vmap(jax.grad(f))

x = jnp.linspace(-2.5, 2.5, 200)
plt.plot(x, jax.vmap(f)(x), label="f(x)")
plt.plot(x, df(x), label="f'(x)", linestyle="--")
plt.axhline(0, color="gray", linewidth=0.5)
plt.legend()
plt.title("A function and its derivative")
plt.show()
```
