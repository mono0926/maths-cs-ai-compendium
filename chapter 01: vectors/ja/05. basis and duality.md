# 基底と双対性 (Basis and Duality)

- ベクトルがある一定の次元数を持つ空間に存在することは見てきました。しかし、それらの次元を定義しているものは何でしょうか？ここで **基底ベクトル (basis vectors)** が登場します。

- **基底 (basis)** とは、冗長性なく、スケーリングと加算（線形結合）によって空間内の他のすべてのベクトルを構築できるベクトルの集合です。それらは空間のビルディングブロック（構成要素）です。

- 基底は以下の2つの条件を満たさなければなりません：
  - **線形独立 (Linearly independent)**: どの基底ベクトルも、他の基底ベクトルから作ることはできない。それぞれが純粋に新しい方向を寄与している。

  - **生成する（張る） (Spanning)**: 空間内のすべてのベクトルを、基底ベクトルの組み合わせとして表現できる。漏れがない。

- 基底に含まれるベクトルの数は、その空間の **次元 (dimension)** に等しくなります。$\mathbb{R}^2$ では2つ、$\mathbb{R}^3$ では3つの基底ベクトルが必要です。

- 最も自然な基底は **標準基底 (standard basis)** であり、各軸に沿った単位ベクトルです：
  - $\mathbb{R}^2$ の場合： $\hat{\mathbf{i}} = (1, 0)$ および $\hat{\mathbf{j}} = (0, 1)$
  - $\mathbb{R}^3$ の場合： $\hat{\mathbf{i}} = (1, 0, 0)$, $\hat{\mathbf{j}} = (0, 1, 0)$, $\hat{\mathbf{k}} = (0, 0, 1)$

- あらゆるベクトルは、これらの基底ベクトルの重み付き和に過ぎません。ベクトル $(3, 2)$ は実際には $3\hat{\mathbf{i}} + 2\hat{\mathbf{j}}$ です。この重み（3 と 2）が、その基底におけるベクトルの **座標 (coordinates)** となります。

- しかし、標準基底だけが有効な基底ではありません。$\mathbb{R}^2$ において、ベクトル $(1, 1)$ と $(-1, 1)$ も基底を形成します。これらは線形独立であり、平面上のあらゆる点に到達できます。同じベクトルであっても、この新しい基底では異なる座標を持つことになります。

- **基底変換 (change of basis)** は、異なるビルディングブロックを使用して同じベクトルを再表現することです。ベクトル自体は動いていません。単に異なる視点からそれを説明しているだけです。

- これは、新しい基底ベクトルを古い座標で書いたものを列（columns）とする **基底変換行列 (change of basis matrix)** $P$ を掛けることで行われます。元に戻すには $P^{-1}$ を掛けます。

- MLでは、基底変換は頻繁に現れます。例えばPCA（主成分分析）は、データが最も変化する方向に軸が揃うような、データの理解がより容易になる新しい基底（主成分）を見つけ出します。

- さて、ここにはさらに深いアイデアが隠されています。$\mathbf{v} = (3, 2)$ と書くとき、座標 3 と 2 は、実際には各基底の方向に沿って $\mathbf{v}$ を「測定」した結果です。最初の座標は「$\mathbf{v}$ の中に $\hat{\mathbf{i}}$ がどれくらい含まれているか？」を問い、2番目は「$\hat{\mathbf{j}}$ がどれくらい含まれているか？」を問うています。

- これらの測定の一つひとつは **線形汎関数 (linear functional)** と呼ばれます。これはベクトルを受け取り、一つの数値を返す関数です。このような線形汎関数のすべての集まりは **双対空間 (dual space)** $V^\ast$ を形成します。

- このように考えてみてください。ベクトルは「オブジェクト」であり、線形汎関数はそれらを測るための「る（ものさし、定規）」です。双対空間は、考えうるすべての「定規」の集合です。

- すべての基底 $\{\mathbf{e}_1, \mathbf{e}_2, \ldots, \mathbf{e}_n\}$ に対して、対応する **双対基底 (dual basis)** $\{\mathbf{e}_1^\ast, \mathbf{e}_2^\ast, \ldots, \mathbf{e}_n^\ast\}$ が存在します。各双対基底ベクトルは、ちょうど一つの座標を抽出します：

```math
\mathbf{e}_i^\ast(\mathbf{e}_j) = \delta_{ij} = \begin{cases} 1 & i = j \text{ のとき} \\ 0 & i \neq j \text{ のとき} \end{cases}
```

- $\mathbf{e}_1^\ast$ は、$\mathbf{e}_1$ に適用されたときは 1 を返し、それ以外には 0 を返します。これは最初の座標を完璧に分離します。

- ドット積はこれら2つの世界を結びつけます。$\mathbf{u} \cdot \mathbf{v}$ を計算するとき、一方のベクトルを、もう一方を測定する「定規」として機能していると考えることができます。ドット積 $\mathbf{u} \cdot \mathbf{v}$ は、$\mathbf{u}$ によって定義される線形汎関数をベクトル $\mathbf{v}$ に適用することと同じです。

- これは、すべてのベクトルが密かに線形汎関数を定義しており、すべての線形汎関数がベクトルによって表現可能であることを意味します。有限次元においては、双対空間は本質的に元の空間の鏡像（ミラーイメージ）です。

- 双対性は今は抽象的に見えるかもしれませんが、多くの実用的なアイデアの根底にあります。座標は双対基底による評価であり、ドット積は双対性のペアリングです。そして、ニューラルネットワークにおけるアテンション（Attention）のような変換は、一方のベクトルセットが他方を「クエリ（問い合わせ）」することで動作しており、これは実質的に双対性が作用しているのです。

## コーディング課題 (CoLab または notebook を使用)

1. 一つのベクトルを2つの異なる基底で表現し、それらが同じ点を表していることを確認してください。独自の基底を作成してみて、ベクトルがどのような座標になるかを確認してみてください。

```python {cmd=true}
import jax.numpy as jnp

v = jnp.array([3.0, 2.0])

# 標準基底：座標は成分そのもの
print(f"Standard basis coords: {v}")

# 新しい基底: (1,1) と (-1,1)
P = jnp.array([[1.0, -1.0],
               [1.0,  1.0]])
new_coords = jnp.linalg.solve(P, v)
print(f"New basis coords: {new_coords}")

# 検証：新しい座標から再構成
reconstructed = new_coords[0] * P[:, 0] + new_coords[1] * P[:, 1]
print(f"Reconstructed: {reconstructed}")
```

2. 双対基底の性質を検証してください：各双対基底ベクトルがちょうど一つの座標を抽出し、他に対してはゼロを返すことを確認します。

```python {cmd=true}
import jax.numpy as jnp

# R3 における標準基底
e1 = jnp.array([1.0, 0.0, 0.0])
e2 = jnp.array([0.0, 1.0, 0.0])
e3 = jnp.array([0.0, 0.0, 1.0])

v = jnp.array([5.0, 3.0, 7.0])

# 各ドット積が一つの座標を抽出する
print(f"e1 · v = {jnp.dot(e1, v)}")
print(f"e2 · v = {jnp.dot(e2, v)}")
print(f"e3 · v = {jnp.dot(e3, v)}")
```
