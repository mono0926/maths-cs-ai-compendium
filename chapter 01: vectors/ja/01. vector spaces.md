# ベクトル空間 (Vector Spaces)

- ベクトル空間を、数学的なオブジェクトが住む特定の「遊び場」と考えてみましょう。それぞれのオブジェクトは **ベクトル (vector)** と呼ばれます。

- 機械学習（ML）における幾何学的な直感を得るために、ベクトルをユークリッド空間内の点とみなし、その座標によって表現することにします。

- ベクトル $\mathbf{a}$ (数学的には小文字の太字で表記されます) は $n$ 個の座標を持ち、それぞれが各軸に沿った位置を表します。

$$\mathbf{a} = [a_1, a_2, a_3]$$

![3次元空間にプロットされたベクトル a = (3, 2, 4) と x, y, z 軸](../../images/vector_3d.svg)

- ベクトル空間内のベクトルは、非常に厳格な、破られることのないルールセットに従います：
  - **ベクトルの加算（組み合わせ）**:
    任意の2つのベクトルを組み合わせて、新しいベクトルを作成できます。
    ベクトルを「移動の指示」と考えてみてください。
    もしベクトル A が「前に3歩進む」であり、ベクトル B が「右に2歩進む」であれば、それらを足す (A + B) ことで、「前に3歩、右に2歩進む」という一つの新しい指示が生まれます。

  - **スカラー倍（スケーリング）**:
    任意のベクトルを、通常の実数（スカラー）を使ってスケーリング（伸縮）できます。
    伸ばしたり、縮めたり、反転させたりできます。
    もしベクトル A が「前に3歩進む」であれば、それを2倍にスケーリングすると「前に6歩進む」になります。
    -1倍にスケーリングすると、完全に反転して「後ろに3歩進む」になります。

- ベクトル空間の **次元 (dimension)** は、それに含まれる独立した方向の数です。$\mathbb{R}^2$ は2次元で（2つの座標が必要）、上記の $\mathbf{a}$ は $\mathbb{R}^3$ に存在します。

- 例えば、任意のオブジェクト（人間など）をベクトルとして表現できます。ここで、$h_1$ = 身長(cm)、$h_2$ = 体重(kg)、$h_3$ = 年齢とします。

$$\mathbf{h} = [185, 75, 30]$$

- これで、人間を表現するベクトルを持つベクトル空間ができました。

- 複数の人間を表現し、それらがどれくらい近いか、または離れているかを見ることができます！

![ベクトルとしての3人：アリスとキャロルは近く、アリスとボブは遠く離れている](../../images/human_vectors.svg)

- さらに多くの特徴（特徴量）を追加して、人間を豊かに表現することができます。これはMLにおいて **特徴量ベクトル (feature vectors)** と呼ばれることがよくあります。

- 特徴量が一意的で意味があるほど、特徴量ベクトルの記述能力が高くなります。これは覚えておくべき重要な要素です。

- 3次元を超えるとベクトルの視覚的な確認が非常に困難になります。これが **線形代数 (Linear Algebra)** と呼ばれる数学の一分野が求められる理由です。

- **線形代数** は、ベクトル、ベクトル空間、およびベクトル間の写像（マッピング）を研究する学問です。

- AI/MLにおけるほぼすべてのものをベクトルとして表現するため、線形代数はこの分野の土台（石杖）となります。

- ベクトルの加算は、視覚的には一方のベクトルの末尾にもう一方を配置し、原点から終点まで線を引くことで実行できます。

![ベクトルの加算：a（赤）にb（青）を加えると、結果として a + b（緑の点線）が得られる](../../images/vector_addition.svg)

- 2つのベクトル $\mathbf{a} = (a_1, a_2)$ と $\mathbf{b} = (b_1, b_2)$ に対して： $\mathbf{a} + \mathbf{b} = (a_1 + b_1, a_2 + b_2)$

- ベクトルは引き算も可能で、加算のすべてのルールが同様に適用されます。

- ベクトルにスカラーを掛けると、そのベクトルは同じ方向にその倍率でスケーリングされます。

![スカラー倍：v（赤）、2v（青、2倍）、-v（紫、反転）](../../images/scalar_multiplication.svg)

- スカラー $c$ とベクトル $\mathbf{v} = (v_1, v_2)$ に対して： $c\mathbf{v} = (cv_1, cv_2)$

- **加法に関する閉鎖性 (Closure under Addition)**: ベクトル空間内の任意の2つのベクトルを足すと、結果もまた同じ空間内のベクトルになります： $\mathbf{u} \in V$ かつ $\mathbf{v} \in V$ ならば、 $\mathbf{u} + \mathbf{v} \in V$

- **スカラー倍に関する閉鎖性 (Closure under Scalar Multiplication)**: ベクトル空間内の任意のベクトルにスカラーを掛けると、結果もまた同じ空間内のベクトルになります： $\mathbf{v} \in V$ かつ $c \in F$ ならば、 $c\mathbf{v} \in V$

- **加法の結合法則 (Associativity of Addition)**: 任意の3つのベクトル $\mathbf{u}, \mathbf{v}, \mathbf{w}$ に対して： $(\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})$

- **加法の交換法則 (Commutativity of Addition)**: 任意の2つのベクトル $\mathbf{u}, \mathbf{v}$ に対して： $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$

![平行四辺形の法則：どちらの経路（uの後にv、またはvの後にu）も同じ点に到達する](../../images/commutativity.svg)

- 平行四辺形を通る両方の経路は、同じ点に到着します。

- **(零ベクトル)**: 任意のベクトル $\mathbf{v}$ に対して $\mathbf{v} + \mathbf{0} = \mathbf{v}$ となるようなベクトル $\mathbf{0}$ が存在します。

![零ベクトル：v + 0 = v](../../images/zero_vector.svg)

- **加法逆元 (Additive Inverse)**: すべてのベクトル $\mathbf{v}$ に対して、$\mathbf{v} + (-\mathbf{v}) = \mathbf{0}$ となるようなベクトル $-\mathbf{v}$ が存在します。

![加法逆元：v（赤）と -v（青）は相殺されて零になる](../../images/additive_inverse.svg)

- **分配法則 1 (Distributivity 1)**: 任意のスカラー $c$ とベクトル $\mathbf{u}, \mathbf{v}$ に対して： $c(\mathbf{u} + \mathbf{v}) = c\mathbf{u} + c\mathbf{v}$

![分配法則：和をスケーリングしたもの（金）は、スケーリングされたベクトルの和に等しい](../../images/distributivity.svg)

- 和をスケーリングしたもの（金）は、スケーリングされた各ベクトルを足し合わせたものと同じ結果になります。

- **分配法則 2 (Distributivity 2)**: 任意のスカラー $c, d$ とベクトル $\mathbf{v}$ に対して： $(c + d)\mathbf{v} = c\mathbf{v} + d\mathbf{v}$

- **スカラー倍の結合法則 (Associativity)**: 任意のスカラー $c, d$ とベクトル $\mathbf{v}$ に対して： $(cd)\mathbf{v} = c(d\mathbf{v})$

- **単位元 (Identity Element)**: 任意のベクトル $\mathbf{v}$ に対して： $1\mathbf{v} = \mathbf{v}$ となります。ここで $1$ はスカラーの体（field）における乗法の単位元です。

- **部分空間 (subspace)** は、大きな遊び場の中にある小さな遊び場です。3次元空間を一つの部屋だと想像してください。部屋の中心を通る平らな紙のシートは部分空間ですし、中心を通る一本のまっすぐなワイヤーも部分空間です。

- 重要な要件は、部分空間が **原点を通らなければならない** ことです。もしその紙のシートを垂直にずらして中心から外すと、零ベクトルがその上に存在しなくなるため、部分空間ではなくなります。

![部分空間：3次元空間内の原点を通る直線と平面](../../images/subspaces.svg)

- ベクトル空間のすべてのルール（加算、スカラー倍、閉鎖性）は、部分空間内でも依然として成り立ちます。部分空間内でベクトルを足したりスカラー倍したりしても、より広い空間へと「はみ出す」ことはありません。

- 原点を通過する直線は1次元の部分空間であり、原点を通過する平面は2次元の部分空間です。そして、空間全体もそれ自身の部分空間です。

- MLでは、部分空間は自然に現れます。高次元のデータは、より低い次元の部分空間上に構造を持っていることがよくあります。PCA（主成分分析）のような手法は、その部分空間を見つけ出すことで、データをより効率的に扱えるようにします。

## コーディング課題 (CoLab または notebook を使用)

1. 分配法則が成り立つことを検証するコードを実行してください。その後、他のルールをテストするためにコードを修正して遊んでみてください！

```python {cmd=true}
import jax.numpy as jnp

u = jnp.array([1, 2])
v = jnp.array([3, 0])
c = 2

lhs = c * (u + v)
rhs = c*u + c*v

print(f"LHS: {lhs}")
print(f"RHS: {rhs}")
```

2. 異なるベクトルを視覚化するコードを実行してください。その後、各軸が位置にどのように影響するかを理解するために、座標の値を変更してみてください。

```python {cmd=true}
import jax.numpy as jnp
import matplotlib.pyplot as plt

# これらのベクトルを変更してみてください！
a = jnp.array([3, 2, 4])
b = jnp.array([1, 4, 2])
c = jnp.array([4, 1, 3])

fig = plt.figure()
ax = fig.add_subplot(111, projection="3d")

for vec, name, color in [(a, "a", "red"), (b, "b", "blue"), (c, "c", "green")]:
    ax.quiver(0, 0, 0, *vec, color=color, arrow_length_ratio=0.1, linewidth=2, label=name)

lim = int(jnp.abs(jnp.stack([a, b, c])).max()) + 1
ax.set_xlim([0, lim]); ax.set_ylim([0, lim]); ax.set_zlim([0, lim])
ax.set_xlabel("X"); ax.set_ylabel("Y"); ax.set_zlabel("Z")
ax.legend()
plt.show()
```
