# 統計的推論 (Statistical Inference)

- 仮説検定は「棄却するかしないか」という、はい/いいえの決定を下します。しかし、多くの場合、推定しているパラメータに対して、より情報量の多い「もっともらしい値の範囲」を知りたいことがあります。それが **信頼区間 (confidence intervals)** が提供するものです。

- **点推定 (point estimate)** は、サンプル平均 $\bar{x}$ のように、サンプルから計算された単一の数値です。これは母集団パラメータに対する最善の推測ですが、それだけでは推定の精密さについては何もわかりません。

- **信頼区間** は、その点推定を不確実性を反映した範囲で包みます。次のような形式をとります：

$$\text{CI} = \bar{x} \pm \text{ME}$$

- **許容誤差 (margin of error; ME)** は、どれほどの信頼度（信頼水準）を求めるか、データにどれほどのばらつきがあるか、そしてサンプルサイズがどれほど大きいかの3点に依存します：

$$\text{ME} = z^\ast \cdot \frac{\sigma}{\sqrt{n}}$$

- ここで $z^\ast$ は、希望する信頼水準に対応する正規分布の棄却限界値です。95% 信頼区間の場合は $z^\ast = 1.96$、99% 信頼区間の場合は $z^\ast = 2.576$ です。

![信頼区間：点推定の両側に許容誤差がある](../images/confidence_interval.svg)

- **95% 信頼区間** が意味するのは、「もし実験を何度も繰り返し、その都度区間を構築したとしたら、それらの区間のうち約 95% が真の母数を含んでいる」ということです。「この特定の区間にパラメータが含まれる確率が 95% である」という意味ではありません。パラメータは固定されており、変動するのは構築される区間の方です。

- **演習例**：50人の身長を測定し、$\bar{x} = 170$ cm、$\sigma = 8$ cm でした。95% 信頼区間を構築してください。

$$\text{ME} = 1.96 \cdot \frac{8}{\sqrt{50}} = 1.96 \cdot 1.131 = 2.22 \text{ cm}$$

$$\text{CI} = [170 - 2.22, \; 170 + 2.22] = [167.78, \; 172.22]$$

- 「真の平均身長は 167.78 cm から 172.22 cm の間にある」と 95% の信頼度で言うことができます。

- $\sigma$ が未知の場合（通常はこちらです）、サンプルの標準偏差 $s$ と t 分布を使用します：

$$\text{CI} = \bar{x} \pm t^\ast_{n-1} \cdot \frac{s}{\sqrt{n}}$$

- 広い区間ほど信頼度は高いですが、精密さは低くなります。狭い区間ほど精密ですが、信頼度は低くなります。サンプルサイズを大きくすることで、信頼度を下げずに区間を狭くすることができます。

- **検出力分析 (Power analysis)** は、実験を実施する前に計画を立てるのに役立ちます。「特定のサイズの効果を、指定した検出力 (power) で検出するには、どれだけのサンプルサイズが必要か？」という問いに答えます。

- 前のファイルで述べたように、検出力 = $1 - \beta$ であり、これは偽である $H_0$ を正しく棄却できる確率です。一般的な目標は 80% の検出力です。

- 有意水準 $\alpha$、検出力 $1-\beta$ で、差 $\delta$ を検出するために必要な z 検定のサンプルサイズは次の通りです：

$$n = \left(\frac{(z_{\alpha/2} + z_{\beta}) \cdot \sigma}{\delta}\right)^2$$

- 例えば、平均身長において 2 cm の差 ($\sigma = 8$) を $\alpha = 0.05$、80% の検出力 ($z_{0.025} = 1.96, z_{0.20} = 0.84$) で検出したい場合：

$$n = \left(\frac{(1.96 + 0.84) \cdot 8}{2}\right)^2 = \left(\frac{22.4}{2}\right)^2 = 11.2^2 \approx 126$$

- 各グループにつき約 126 人が必要になります。

- 検出力分析によって、2つのよくある間違いを防ぐことができます：実際の効果を検出するには小さすぎる実験を行うこと（検出力不足）、または必要以上に大規模な実験にリソースを浪費すること（過剰検出力）。

- **モンテカルロ法 (Monte Carlo methods)** は、解析的に解くのが困難または不可能な問題を解くためにランダムサンプリングを使用します。核心となるアイデアは、「何かを正確に計算できないのであれば、何度もシミュレーションを行い、その結果を近似値として使用する」というものです。

- 名前はモンテカルロのカジノに由来しており、ランダム性の役割への敬意が込められています。これらの手法は、積分値の推定、モデルの不確実性の評価、複雑な分布の近似など、ML の中心的な役割を担っています。

- 一般的なモンテカルロの手順：
  - 可能な入力のドメインを定義する
  - そのドメインからランダムに入力を生成する
  - 各入力に対して関数を評価する
  - 結果を集計する（平均、カウントなど）

- 古典的な例は $\pi$ の推定です。原点を中心とする一辺の長さが 2 の正方形と、その中に内接する半径 1 の円を想像してください。正方形の面積は 4 で、円の面積は $\pi$ です。

![正方形の中に内接する円。ランダムな点が円の内外で色分けされている](../images/monte_carlo_pi.svg)

- 正方形内にランダムな点（一様分布）を落とします。円の中に入った点の割合は $\pi/4$ に近似されます：

$$\pi \approx 4 \times \frac{\text{円の中に入った点}}{\text{全投下点}}$$

- 点 $(x, y)$ が円の中にある条件は $x^2 + y^2 \le 1$ です。点を多く投げれば投げるほど、推定値は真の $\pi$ の値に近づきます。

- ML においてモンテカルロ法は以下のような場所で現れます：
  - **モンテカルロ・ドロップアウト**：ドロップアウトを有効にした状態で推論を複数回実行し、予測の不確実性を推定する。
  - **MCMC (Markov Chain Monte Carlo)**：ベイズモデルにおいて複雑な事後分布からサンプリングを行う。
  - **方策勾配法 (Policy gradient methods)**：強化学習においてトラジェクトリ（軌跡）をサンプリングすることで勾配を推定する。

- **因子分析 (Factor analysis)** は、観測された変数間の相関を説明する隠れた（潜在的な）変数を発見するための手法です。もし 10 個の性格診断の質問が、3 つの根底にある特性（外向性、調和性、勤勉性）で説明できるのであれば、因子分析はそれらの特性を見つけ出します。

- このモデルでは、各観測変数 $x_i$ は、少数の潜在因子 $f_j$ の線形結合にノイズを加えたものであると仮定します：

$$x_i = \lambda_{i1} f_1 + \lambda_{i2} f_2 + \ldots + \lambda_{ik} f_k + \epsilon_i$$

- $\lambda$ 値は **因子負荷量 (factor loadings)** と呼ばれ、各観測変数が各因子にどれほど強く関連しているかを示します。これは Chapter 2 の行列分解と直結しており、因子分析は固有値分解や SVD（特異値分解）と密接な関係があります。

- **実験計画法 (Experimental design)** は、有効な結論を導き出せるように実験を構造化するための技術です。計画が不適切であれば、たとえ大規模なデータセットであっても役に立たなくなってしまいます。

- 適切に設計された実験の主要構成要素：
  - **独立変数 (Independent variable; IV)**：操作するもの（例：薬の投与量、モデルのアーキテクチャ）。
  - **従属変数 (Dependent variable; DV)**：測定するもの（例：回復時間、精度）。
  - **対照群 (Control group)**：治療（処置）を受けない（またはプラセボを受ける）グループ。比較のための基準（ベースライン）を提供します。
  - **ランダム割付 (Random assignment)**：参加者をランダムにグループに割り当てることで、測定していない交絡変数のバランスを取ります。

- **一般的な実験計画**：
  - **完全無作為化法 (Completely randomised design)**：被験者をランダムに処置グループに割り当てます。グループが同等である場合にシンプルで効果的です。
  - **乱塊法 (Randomised block design)**：被験者をまず特性（例：年齢）ごとにブロックに分け、各ブロック内で処置をランダムに割り当てます。これにより、ブロック因子に由来する変動が抑えられます（層化サンプリングと考え方は似ています）。
  - **要因計画法 (Factorial design)**：複数の独立変数を同時にテストします。$2 \times 3$ 要因計画は、一方の変数が 2 レベル、もう一方が 3 レベルあり、計 6 通りの処置の組み合わせを持ちます。これにより、一方の変数の効果が他方の変数のレベルに依存する **交互作用 (interactions)** を検出できます。
  - **クロスオーバー法 (Crossover design)**：各被験者がすべての処置を順番に受けます（処置の間には効果が抜けるのを待つウォッシュアウト期間を設けます）。各被験者が自分自身の対照（コントロール）となるため、個体差の影響を軽減できます。

- ML の実験においても、これらの原則は極めて重要です。モデルを比較する際には、ランダムシード、データセットの分割（スプリット）、ハードウェアなどを制御する必要があります。交差検証はクロスオーバー法の一種です。一度に1つのコンポーネントを取り除くアブレーション研究 (ablation studies) は、要因計画法の論理に従っています。

## コーディングタスク (CoLab または notebook を使用)

1. 身長の例について 95% 信頼区間を構築し、異なる信頼水準やサンプルサイズで実験してください。

```python {cmd=true}
import jax.numpy as jnp

x_bar = 170.0    # サンプル平均
sigma = 8.0      # 母標準偏差 (既知とする)
n = 50           # サンプルサイズ

# 一般的な信頼水準に対応する棄却限界値
z_stars = {0.90: 1.645, 0.95: 1.960, 0.99: 2.576}

for conf, z_star in z_stars.items():
    me = z_star * (sigma / jnp.sqrt(n))
    lower, upper = x_bar - me, x_bar + me
    print(f"{conf*100:.0f}% 信頼区間: [{lower:.2f}, {upper:.2f}]  (許容誤差 = {me:.2f})")
```

2. モンテカルロ・シミュレーションを使用して $\pi$ を推定してください。ポイントの数が増えるにつれて推定値が収束していく様子をプロットしてください。

```python {cmd=true}
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

key = jax.random.PRNGKey(42)

# [-1, 1] x [-1, 1] の範囲でランダムな点を生成
n_points = 100_000
k1, k2 = jax.random.split(key)
x = jax.random.uniform(k1, shape=(n_points,), minval=-1, maxval=1)
y = jax.random.uniform(k2, shape=(n_points,), minval=-1, maxval=1)

# どの点が単位円の内側にあるかを確認
inside = (x**2 + y**2) <= 1.0
cumulative_inside = jnp.cumsum(inside)
counts = jnp.arange(1, n_points + 1)
pi_estimates = 4.0 * cumulative_inside / counts

plt.figure(figsize=(10, 4))
plt.plot(pi_estimates, color="#3498db", alpha=0.7, linewidth=0.5)
plt.axhline(y=jnp.pi, color="#e74c3c", linestyle="--", label=f"π = {jnp.pi:.6f}")
plt.xlabel("点の数")
plt.ylabel("π の推定値")
plt.title("π のモンテカルロ推定")
plt.legend()
plt.ylim(2.8, 3.5)
plt.show()

print(f"最終的な推定値: {pi_estimates[-1]:.6f}")
print(f"真の値:         {jnp.pi:.6f}")
print(f"誤差:           {abs(pi_estimates[-1] - jnp.pi):.6f}")
```

3. 簡単な検出力分析を実行してください：指定された効果サイズと標準偏差に対して必要なサンプルサイズを計算し、シミュレーションで検証してください。

```python {cmd=true}
import jax
import jax.numpy as jnp

# パラメータ
delta = 2.0      # 効果量 (平均の差)
sigma = 8.0      # 母標準偏差
alpha = 0.05
power_target = 0.80

# 理論的なサンプルサイズの計算
z_alpha = 1.96   # 両側、alpha=0.05
z_beta = 0.84    # power=0.80
n_required = ((z_alpha + z_beta) * sigma / delta) ** 2
print(f"グループあたりの必要数 n: {n_required:.0f}")

# シミュレーションで検証
key = jax.random.PRNGKey(7)
n = int(jnp.ceil(n_required))
n_sims = 5000
rejections = 0

for _ in range(n_sims):
    key, k1, k2 = jax.random.split(key, 3)
    group_a = jax.random.normal(k1, shape=(n,)) * sigma + 50
    group_b = jax.random.normal(k2, shape=(n,)) * sigma + 50 + delta
    pooled_se = jnp.sqrt(2 * sigma**2 / n)
    z = (group_b.mean() - group_a.mean()) / pooled_se
    # norm.cdf は jax.scipy.stats.norm 経由
    p = 2 * (1 - __import__("jax").scipy.stats.norm.cdf(jnp.abs(z)))
    if p <= alpha:
        rejections += 1

print(f"シミュレーションされた検出力: {rejections/n_sims:.3f}")
print(f"目標検出力:                  {power_target:.3f}")
```

4. 信頼区間の幅がサンプルサイズによってどのように変化するかを可視化してください。より多くのデータを収集することで、より精密な推定が可能になる理由を確認してください。

```python {cmd=true}
import jax.numpy as jnp
import matplotlib.pyplot as plt

sigma = 8.0
z_star = 1.96  # 95% 信頼水準

sample_sizes = jnp.array([10, 20, 30, 50, 100, 200, 500, 1000], dtype=jnp.float32)
margins = z_star * sigma / jnp.sqrt(sample_sizes)

plt.figure(figsize=(8, 4))
plt.bar([str(int(n)) for n in sample_sizes], margins, color="#3498db", alpha=0.7)
plt.xlabel("サンプルサイズ")
plt.ylabel("許容誤差 (cm)")
plt.title("95% 信頼区間の許容誤差は、サンプルが大きくなるほど小さくなる")
plt.show()
```
