# サンプリング (Sampling)

- 理想的な世界では、関心のあるグループの全メンバーを測定することになるでしょう。しかし現実には、それはほとんど不可能です。すべての有権者を調査し、すべての電球をテストし、すべての患者をスキャンすることはできません。そのため、**サンプル (sample; 標本)** を抽出し、それを使用して全体について学びます。

- **母集団 (population)** は、研究したい個人または項目の完全な集合です。**サンプル (sample; 標本)** は、実際に観察するサブセットです。

- **パラメータ (parameter; 母数)** は、母集団を記述する数値です（例：ある国の全成人の真の平均身長）。

- **統計量 (statistic)** は、サンプルから計算された数値です（例：測定した500人の平均身長）。統計量はパラメータを推定するために使用されます。

- 結論の質は、どのようにサンプルを選択したかに完全に依存します。分析がいかに洗練されていても、偏った（バイアスのある）サンプルからは偏った結論しか得られません。

- **サンプリング枠 (sampling frame)** は、実際にサンプルを抽出する対象となる個人のリストです。理想的にはこれは母集団と完全に一致しますが、実際にはギャップが生じます。

- 例えば、電話で調査を行う場合、電話を持っていない人はすべて漏れてしまいます。このサンプリング枠と母集団の差を **カバレッジ誤差 (coverage error)** と呼びます。

- **サンプリング誤差 (sampling error)** は、サンプルの統計量と母集団のパラメータの間に自然に生じる不一致です。

- 完全に無作為なサンプルであっても、母集団と完全に一致することはありません。サンプルサイズを大きくすることで、サンプリング誤差を減らすことができます。

- サンプリングには大きく分けて、確率サンプリングと非確率サンプリングの2つのファミリーがあります。

- **確率サンプリング (Probability sampling)** は、母集団のすべてのメンバーが、既知のゼロではない選択される確率を持っていることを意味します。これにより、不確実性を定量化し、結果を一般化することができます。

- **単純無作為抽出 (Simple random sampling)**：すべての個人の選択される確率が等しく、サイズ $n$ のすべての可能なサンプルが同様に確からしい抽出方法です。すべての名前を帽子に入れ、目隠しをして引くようなものです。

- **層化抽出 (Stratified sampling)**：共通の特徴（年齢層、地域など）に基づいて母集団を重複のないグループ（層; strata）に分け、各層から無作為にサンプリングします。これにより、すべてのグループが確実に代表され、層同士が異なる場合には分散を抑えることができます。

- **クラスター抽出 (Cluster sampling)**：母集団をグループ（クラスター）に分け、いくつかのクラスターを無作為に選択し、選ばれたクラスター内の全員を調査対象にします。これは、地区全体の個々の学生ではなく学校全体をサンプリングするように、母集団が地理的に分散している場合に実用的です。

- **系統抽出 (Systematic sampling)**：無作為な開始点を選び、そこからリストの $k$ 番目ごとの個人を選択します。例えば、7人目から始めて10人おき（7, 17, 27, ...）に抽出します。実装は簡単ですが、リストに隠れたパターンがある場合にバイアスが導入される可能性があります。

![3つの確率サンプリング手法の比較：単純無作為、層化、クラスター](../images/sampling_methods.svg)

- **非確率サンプリング (Non-probability sampling)** は、すべてのメンバーに既知の選択確率を与えません。結果を厳密に一般化することはできませんが、多くの場合、より迅速で安価です。

- **便宜的サンプリング (Convenience sampling)**：最も連絡を取りやすい人を選択します。ショッピングモールで人々にアンケートを取ることは便利ですが、そこに来ない人々を見落とすことになります。

- **割当サンプリング (Quota sampling)**：層化抽出に似ていますが、無作為性がありません。調査員は、各グループからアクセスしやすい個人をピックアップして、割当（例：男性50人、女性50人）を満たします。

- **スノーボールサンプリング (Snowball sampling)**：数人の参加者から始め、その人たちに他の人を紹介してもらいます。到達が困難な母集団（例：希少疾患の研究）に有用ですが、つながりのある個人に大きく偏ります。

- サンプリング方法が決まったら、「もし別のサンプルを抽出していたら、別の統計量が得られただろうか？」という疑問が生じます。ほぼ確実に「はい」です。同じサイズのあらゆる可能なサンプルにわたる統計量（サンプル平均など）の分布を **標本分布 (sampling distribution)** と呼びます。

- 30人のサンプルを1,000回抽出し、それぞれの平均身長を計算することを想像してください。それら1,000個の平均が1つの分布を形成します。いくつかの平均は真の母平均より少し高く、いくつかは少し低くなり、ほとんどは真の値の周りに集まります。

- この標本分布の標準偏差を **標準誤差 (standard error; SE)** と呼びます：

$$SE = \frac{\sigma}{\sqrt{n}}$$

- サンプルサイズ $n$ が大きくなるにつれて、標準誤差が小さくなることに注目してください。大きなサンプルほど、より精密な推定が可能です。サンプルサイズを4倍にすると、標準誤差は半分になります。

- 統計学において最も重要な結果は **中心極限定理 (Central Limit Theorem; CLT)** です。これは、「元の母集団の形状に関わらず、サンプルサイズが大きくなるにつれて、サンプル平均の分布は正規分布に近づく」というものです。

![CLT: 歪んだ母集団から抽出されたサンプル平均は正規分布になる](../images/central_limit_theorem.svg)

- より正確には、平均 $\mu$ と有限の分散 $\sigma^2$ を持つ任意の分布からの独立した観測値 $X_1, X_2, \ldots, X_n$ があるとき、$n$ が大きくなるにつれて：

$$\bar{X} \approx \text{Normal}\!\left(\mu, \frac{\sigma^2}{n}\right)$$

- 中心極限定理は、推測統計学のほとんどを支える定理です。サンプルが十分に大きければ、基礎となるデータが正規分布に従っていなくても、正規分布を近似として使用することができます。

- 「十分に大きい」とはどれくらいでしょうか？ 一般的な経験則としては $n \ge 30$ ですが、これは母集団がどれほど非正規であるかに依存します。大きく歪んだ分布の場合は、もっと必要かもしれません。ほぼ対称な母集団であれば、$n = 10$ でも十分な場合があります。

- 中心極限定理には3つの重要な条件があります：
  - **独立性 (Independence)**：各観測値が他の観測値に影響を与えないこと。
  - **有限の分散 (Finite variance)**：母分散が存在すること（一部のエキゾチックな分布は除外されます）。
  - **同一の分布 (Identical distribution)**：すべての観測値が同じ分布から来ていること（独立同一分布; i.i.d.）。

## コーディングタスク (CoLab または notebook を使用)

1. 中心極限定理を視覚的に示してください。大きく歪んだ分布からサンプルを抽出し、サンプル平均を計算して、平均のヒストグラムがベル型（正規分布）になっていく様子を確認してください。

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

key = jax.random.PRNGKey(0)

# 指数分布 (非常に大きく歪んでいる)
population = jax.random.exponential(key, shape=(100_000,))

fig, axes = plt.subplots(1, 4, figsize=(14, 3))
sample_sizes = [1, 5, 30, 100]

for ax, n in zip(axes, sample_sizes):
    keys = jax.random.split(key, 2000)
    means = jnp.array([jax.random.choice(k, population, shape=(n,)).mean() for k in keys])
    ax.hist(means, bins=40, color="#3498db", alpha=0.7, density=True)
    ax.set_title(f"n = {n}")
    ax.set_xlim(0, 4)

fig.suptitle("CLT: n が増えるにつれてサンプル平均は正規分布に近づく", fontsize=13)
plt.tight_layout()
plt.show()
```

2. 単純無作為抽出と層化抽出を比較してください。異なるグループを持つ母集団を作成し、層化抽出の方が推定値の分散が低くなることを示してください。

```python
import jax
import jax.numpy as jnp

key = jax.random.PRNGKey(42)

# 母集団: 2つの異なるグループ
group_a = jax.random.normal(key, shape=(500,)) + 10   # 平均 ~10
key, subkey = jax.random.split(key)
group_b = jax.random.normal(subkey, shape=(500,)) + 20  # 平均 ~20
population = jnp.concatenate([group_a, group_b])

# 単純無作為抽出: 1000回の試行、サンプルサイズ 20
srs_means = []
for i in range(1000):
    key, subkey = jax.random.split(key)
    sample = jax.random.choice(subkey, population, shape=(20,), replace=False)
    srs_means.append(sample.mean())
srs_means = jnp.array(srs_means)

# 層化抽出: 各グループから10人ずつ
strat_means = []
for i in range(1000):
    key, k1, k2 = jax.random.split(key, 3)
    s_a = jax.random.choice(k1, group_a, shape=(10,), replace=False)
    s_b = jax.random.choice(k2, group_b, shape=(10,), replace=False)
    strat_means.append(jnp.concatenate([s_a, s_b]).mean())
strat_means = jnp.array(strat_means)

print(f"単純無作為 - 平均: {srs_means.mean():.3f}, 標準偏差: {srs_means.std():.3f}")
print(f"層化抽出   - 平均: {strat_means.mean():.3f}, 標準偏差: {strat_means.std():.3f}")
print(f"層化抽出により分散が {(1 - strat_means.var()/srs_means.var())*100:.1f}% 減少しました")
```

3. サンプルサイズが標準誤差にどのように影響するかを調査してください。標準誤差をサンプルサイズに対してプロットし、$1/\sqrt{n}$ の関係を確認してください。

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

key = jax.random.PRNGKey(7)
population = jax.random.normal(key, shape=(50_000,)) * 10 + 50

sample_sizes = [5, 10, 20, 50, 100, 200, 500, 1000]
std_errors = []

for n in sample_sizes:
    means = []
    for _ in range(500):
        key, subkey = jax.random.split(key)
        sample = jax.random.choice(subkey, population, shape=(n,))
        means.append(sample.mean())
    std_errors.append(jnp.array(means).std())

plt.figure(figsize=(8, 4))
plt.plot(sample_sizes, std_errors, "o-", color="#e74c3c", label="観測された標準誤差")
theoretical = population.std() / jnp.sqrt(jnp.array(sample_sizes, dtype=jnp.float32))
plt.plot(sample_sizes, theoretical, "--", color="#3498db", label="σ/√n (理論値)")
plt.xlabel("サンプルサイズ (n)")
plt.ylabel("標準誤差")
plt.legend()
plt.title("大きなサンプルほど標準誤差は小さくなる")
plt.show()
```
