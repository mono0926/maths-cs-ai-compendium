# 仮説検定 (Hypothesis Testing)

- 統計学は単にデータを記述するだけではありません。多くの場合、何らかの決定を下す必要があります。新薬は効くのか？ 片方のアルゴリズムはもう一方より速いのか？ 平均値は変化したのか？ 仮説検定は、データを使用してこれらの疑問に答えるための構造化されたフレームワークを提供します。

- 考え方はシンプルです。まず、何も変わっていない（「帰無仮説」）と仮定し、次に、データがその仮定の下では信じがたいほど極端なものかどうかを確認します。

- **帰無仮説 (null hypothesis)** ($H_0$) はデフォルトの主張であり、通常は「効果がない」または「差がない」という声明です。例：「平均配達時間は依然として30分である」や「新モデルは旧モデルより優れていない」。

- **対立仮説 (alternative hypothesis)** ($H_1$ または $H_a$) は、代わりに真であると疑っている内容です。「平均配達時間は変化した」や「新モデルの方が優れている」。

- $H_1$ を直接証明することはありません。代わりに、「もし $H_0$ が真だとしたら、これほど極端なデータが得られる確率はどれくらいか？」と問いかけます。その確率が非常に低い場合、$H_0$ を棄却し、$H_1$ を支持します。

- **検定統計量 (test statistic)** は、サンプルの結果が $H_0$ の予測からどれだけ離れているかを要約した単一の数値です。テストごとに異なる公式を使用しますが、論理は常に同じです。観測値と期待値の間の距離を測定します。

- **p値 (p-value)** は、$H_0$ が真であると仮定した場合に、現在得られているデータ、またはそれ以上に極端な結果が得られる確率です。p値が小さいことは、$H_0$ の下ではそのデータが驚くべきものであることを意味します。

- **有意水準 (significance level)** ($\alpha$) は、データを見る前に設定するしきい値です。$p \le \alpha$ であれば、$H_0$ を **棄却 (reject)** します。一般的な選択肢は $\alpha = 0.05$ (5%) や $\alpha = 0.01$ (1%) です。

![棄却域が網掛けされ、検定統計量がマークされ、p値の領域が強調表示された正規曲線](../images/hypothesis_test.svg)

- 網掛けされた部分は **棄却域 (rejection regions)** です。検定統計量がそこに着地した場合、データは $H_0$ の下では十分に驚くべきものとみなされ、棄却されます。緑色の領域は、特定の検定統計量に対する p値を示しています。

- ステップバイステップの手順は次の通りです：
  - **ステップ 1**：$H_0$ と $H_1$ を設定する
  - **ステップ 2**：有意水準 $\alpha$ を選択する
  - **ステップ 3**：データを収集し、検定統計量を計算する
  - **ステップ 4**：p値を求める（または検定統計量を棄却限界値と比較する）
  - **ステップ 5**：$p \le \alpha$ ならば $H_0$ を棄却する。そうでなければ $H_0$ を棄却しない

- **演習例**：ボルト工場が、ボルトの平均長さは 10 cm であると主張しています。あなたが36個のボルトを測定したところ、サンプル平均は 10.3 cm でした。既知の母標準偏差は 0.9 cm です。平均が変化したという証拠はあるでしょうか？

- $H_0$: $\mu = 10$, $H_1$: $\mu \neq 10$, $\alpha = 0.05$

- 検定統計量（$\sigma$ が既知で $n$ が大きいため、z検定）：

$$z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}} = \frac{10.3 - 10}{0.9 / \sqrt{36}} = \frac{0.3}{0.15} = 2.0$$

- $\alpha = 0.05$ の両側検定の場合、棄却限界値（クリティカル値）は $\pm 1.96$ です。私たちの $z = 2.0 > 1.96$ なので、$H_0$ を棄却します。p値は約 0.046 であり、0.05 未満です。

- 結論：ボルトの平均長さが 10 cm とは異なるという統計的に有意な証拠があります。

- **片側検定 (one-tailed test)** は、特定の方向への効果を確認します（$H_1$: $\mu > 10$ または $\mu < 10$）。$\alpha$ 全体が片方の裾に割り当てられるため、その方向への効果を検出しやすくなりますが、逆方向の効果を検出することは不可能です。

- **両側検定 (two-tailed test)** は、あらゆる方向の差異を確認します（$H_1$: $\mu \neq 10$）。$\alpha$ は両方の裾に分割されます（それぞれ $\alpha/2$）。これはより保守的ですが、どちらの方向の変化も捉えることができます。

- 優れた手順を踏んでいても、間違いは起こります。エラーには正確に2つのタイプがあります：

![第1種および第2種の過誤を示す2x2のグリッド：現実 vs 決定](../images/type_errors.svg)

- **第1種の過誤 (Type I Error)**（偽陽性）：実際には真である $H_0$ を棄却してしまうこと。この確率は $\alpha$ であり、有意水準を選択することで制御できます。火が出ていないのに火災報知器が鳴るようなものです。

- **第2種の過誤 (Type II Error)**（偽陰性）：実際には偽である $H_0$ を棄却し損ねること。この確率は $\beta$ です。本当の火災の際に火災報知器が鳴らないようなものです。

- **検出力 (Power)** は $1 - \beta$ であり、偽である $H_0$ を正しく棄却できる確率です。検出力が高いほど、実際の効果を検出するのが得意であることを意味します。検出力は次の場合に高まります：
  - 真の **効果量 (effect size)** が大きい（大きな差ほど検出しやすい）
  - サンプルサイズが大きい（データが多いほど精度が高まる）
  - 有意水準 $\alpha$ が大きい（ただし、第1種の過誤のリスクは高まる）
  - ばらつき（ノイズ）が小さい

- 第1種の過誤と第2種の過誤の間にはトレードオフがあります。 $\alpha$ を下げる（偽陽性に慎重になる）と、$\beta$ が上がります（偽陰性が増える）。固定されたサンプルサイズで、両方を同時に最小化することはできません。

- **パラメトリック検定 (Parametric tests)** は、データが特定の分布（通常は正規分布）に従っていると仮定します。仮定が満たされている場合、より高い検出力を持ちます。

- **z検定 (Z-test)**：$\sigma$ が既知で $n$ が大きい ($n \ge 30$) 場合に、サンプル平均を特定の値と比較します。検定統計量：

$$z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}$$

- **t検定 (T-test)**：$\sigma$ が未知（サンプルから推定される）か、 $n$ が小さい場合の z検定に相当します。正規分布よりも裾が重い **t分布** を使用します。裾が重いことで、$\sigma$ を推定することから生じる追加の不確実性を考慮に入れます。

$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$

- t分布には **自由度 (degrees of freedom)** ($df = n - 1$) と呼ばれるパラメータがあります。$df$ が増えるにつれて、t分布は正規分布に近づきます。

- t検定にはいくつかの種類があります：
  - **1標本t検定 (One-sample t-test)**：サンプル平均が特定の値と異なるか？
  - **独立2標本t検定 (Independent two-sample t-test)**：2つの独立したグループの平均が異なるか？
  - **対応のあるt検定 (Paired t-test)**：2つの関連する測定値の平均が異なるか（例：同じ被験者に対する治療の前後の比較）？

- **分散分析 (ANOVA; Analysis of Variance)**：3つ以上のグループの平均が等しいかどうかをテストします。複数の t検定を実行する（これは第1種の過誤率を増大させます）代わりに、ANOVA は「群間分散」と「群内分散」を比較することで単一のテストを行います。

$$F = \frac{\text{群間分散}}{\text{群内分散}}$$

- F値が大きいほど、グループ間の差異がランダムな変動から期待される以上に大きいことを意味します。

- **ノンパラメトリック検定 (Non-parametric tests)** は、データの分布に関する仮定をほとんど置きません。生の数値ではなく「順位」に基づいて計算するため、外れ値や非正規性に対してロバストです。

- **カイ二乗検定 (Chi-square test)** ($\chi^2$)：観測された頻度が期待される頻度と一致するかどうかをテストします。カテゴリカルデータに使用されます。例：赤、青、緑の車の割合が、メーカーの主張する割合と一致するか？

$$\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}$$

- **マン・ホイットニーのU検定 (Mann-Whitney U test)**：独立2標本t検定のノンパラメトリック版です。順位を比較することで、一方のグループが他方よりも大きな値を持つ傾向があるかどうかをテストします。

- **ウィルコクソンの符号付順位検定 (Wilcoxon signed-rank test)**：対応のあるt検定のノンパラメトリック版です。差の大きさと方向を見て、対応のある観測値を比較します。

- **クラスカル・ウォリス検定 (Kruskal-Wallis test)**：一元配置分散分析 (one-way ANOVA) のノンパラメトリック版です。すべてのグループにわたって順位を比較することで、複数のグループが同じ分布から来ているかどうかをテストします。

- **適合度検定 (Goodness-of-fit tests)**：データが特定の理論的な分布に従っているかどうかを確認します。カイ二乗適合度検定は直感的な検定方法の1つです。

- **正規性検定 (Normality tests)**：データが正規分布に従っているかどうかを具体的に確認します。代表的なものに、小サンプルに強い **シャピロ・ウィルク検定 (Shapiro-Wilk test)** や、サンプルの累積分布関数 (CDF) を理論的な CDF と比較する **コルモゴロフ・スミルノフ検定 (Kolmogorov-Smirnov test)** があります。

- 機械学習では、モデルの性能を比較する際に仮説検定が現れます。モデル A が 92% の精度、モデル B が 91% の精度を達成した場合、その差は本物なのか、それとも単なるノイズなのか？ 交差検証のスコアに対して対応のある t検定を行うことで、この疑問に答えることができます。

## コーディングタスク (CoLab または notebook を使用)

1. 本文に出てきたボルト工場の例について z検定を実行してください。検定統計量と p値を計算し、判定を下してください。

```python
import jax.numpy as jnp
from jax.scipy.stats import norm

x_bar = 10.3    # サンプル平均
mu_0 = 10.0     # 帰無仮説の値
sigma = 0.9     # 既知の母標準偏差
n = 36          # サンプルサイズ
alpha = 0.05

# 検定統計量
z = (x_bar - mu_0) / (sigma / jnp.sqrt(n))
print(f"z = {z:.4f}")

# p値 (両側)
p_value = 2 * (1 - norm.cdf(jnp.abs(z)))
print(f"p-value = {p_value:.4f}")
print(f"H₀ を棄却するか？ {p_value <= alpha}")
```

2. 第1種の過誤のシミュレーション：$H_0$ が真であるとき、誤って棄却してしまうことはどれくらいあるでしょうか？ 10,000 回の実験を行い、棄却率が $\alpha$ と一致することを確認してください。

```python
import jax
import jax.numpy as jnp
from jax.scipy.stats import norm

key = jax.random.PRNGKey(0)
mu_0 = 50.0
sigma = 10.0
n = 30
alpha = 0.05
n_experiments = 10_000

rejections = 0
for i in range(n_experiments):
    key, subkey = jax.random.split(key)
    sample = mu_0 + sigma * jax.random.normal(subkey, shape=(n,))
    z = (sample.mean() - mu_0) / (sigma / jnp.sqrt(n))
    p_value = 2 * (1 - norm.cdf(jnp.abs(z)))
    if p_value <= alpha:
        rejections += 1

print(f"棄却率: {rejections/n_experiments:.4f}")
print(f"期待値 (α):   {alpha}")
```

3. 2つのグループに対して、t検定とマン・ホイットニーのU検定を比較してください。一方のグループの平均がわずかに高いデータを生成し、どちらのテストがその差を検出するかを確認してください。

```python
import jax
import jax.numpy as jnp

key = jax.random.PRNGKey(99)
k1, k2 = jax.random.split(key)

group_a = jax.random.normal(k1, shape=(25,)) * 5 + 100
group_b = jax.random.normal(k2, shape=(25,)) * 5 + 103  # 平均がわずかに高い

# 独立2標本t検定 (等分散を仮定)
n_a, n_b = len(group_a), len(group_b)
mean_a, mean_b = group_a.mean(), group_b.mean()
pooled_var = ((n_a - 1) * group_a.var() + (n_b - 1) * group_b.var()) / (n_a + n_b - 2)
se = jnp.sqrt(pooled_var * (1/n_a + 1/n_b))
t_stat = (mean_a - mean_b) / se
print(f"T検定統計量: {t_stat:.4f}")

# マン・ホイットニー: group_a の値が group_b の値を下回る回数をカウント
u_stat = jnp.sum(group_a[:, None] < group_b[None, :])
print(f"マン・ホイットニー U:   {u_stat}")
print(f"\nグループ A 平均: {mean_a:.2f}, グループ B 平均: {mean_b:.2f}")
```
