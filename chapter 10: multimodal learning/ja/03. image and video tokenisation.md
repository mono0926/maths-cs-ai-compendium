# 画像と動画のトークン化

- **なぜ画像をトークン化するのか**: 連続的なピクセルと、離散的な言語モデルの語彙（ボキャブラリ）の橋渡しをする
- **VQ-VAE**: ベクトル量子化、コードブック学習、コミットメント損失
- **VQ-GAN**: VQ-VAE と敵対的訓練を組み合わせ、より高い忠実度（フィデリティ）を実現する
- **残留量子化 (Residual quantisation)** とマルチスケール・コードブック
- **画像トークナイザー**: DALL-E トークナイザー、LlamaGen、Cosmos トークナイザー
- **動画のトークン化**: 時間方向の圧縮、3D VQ-VAE、因果的動画トークナイザー (Causal video tokenisers)
- **連続トークン vs 離散トークン**: いつ量子化し、いつ投影 (Project) すべきか
- **応用**: 自己回帰的な画像生成、統合された視覚と言語のトークン
